<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference/API · Roots</title><meta name="title" content="Reference/API · Roots"/><meta property="og:title" content="Reference/API · Roots"/><meta property="twitter:title" content="Reference/API · Roots"/><meta name="description" content="Documentation for Roots."/><meta property="og:description" content="Documentation for Roots."/><meta property="twitter:description" content="Documentation for Roots."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="Roots logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">Roots</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../roots/">Overview</a></li><li class="is-active"><a class="tocitem" href>Reference/API</a><ul class="internal"><li><a class="tocitem" href="#The-find_zero-and-find_zeros-functions"><span>The <code>find_zero</code>  and <code>find_zeros</code> functions</span></a></li><li><a class="tocitem" href="#CommonSolve-interface"><span>CommonSolve interface</span></a></li><li><a class="tocitem" href="#Classical-methods-based-on-derivatives"><span>Classical  methods  based on derivatives</span></a></li><li><a class="tocitem" href="#Derivative-free-methods"><span>Derivative free methods</span></a></li><li><a class="tocitem" href="#Bracketing-methods"><span>Bracketing methods</span></a></li><li><a class="tocitem" href="#Non-simple-zeros"><span>Non-simple zeros</span></a></li><li><a class="tocitem" href="#Hybrid-methods"><span>Hybrid  methods</span></a></li><li><a class="tocitem" href="#All-zeros"><span>All zeros</span></a></li><li><a class="tocitem" href="#Rates-of-convergence"><span>Rates of convergence</span></a></li><li><a class="tocitem" href="#Convergence"><span>Convergence</span></a></li><li><a class="tocitem" href="#Simplified-versions"><span>Simplified versions</span></a></li><li><a class="tocitem" href="#MATLAB-interface"><span>MATLAB interface</span></a></li><li><a class="tocitem" href="#Tracking-iterations"><span>Tracking iterations</span></a></li></ul></li><li><a class="tocitem" href="../geometry-zero-finding/">Geometry</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference/API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference/API</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaMath/Roots.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaMath/Roots.jl/blob/master/docs/src/reference.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Reference/API"><a class="docs-heading-anchor" href="#Reference/API">Reference/API</a><a id="Reference/API-1"></a><a class="docs-heading-anchor-permalink" href="#Reference/API" title="Permalink"></a></h1><p>The <code>Roots</code>  package provides several  different  algorithms  to solve <code>f(x)=0</code>.</p><ul><li><a href="#Roots.Roots"><code>Roots.Roots</code></a></li><li><a href="#Roots.A42"><code>Roots.A42</code></a></li><li><a href="#Roots.AbstractThukralBMethod"><code>Roots.AbstractThukralBMethod</code></a></li><li><a href="#Roots.AlefeldPotraShi"><code>Roots.AlefeldPotraShi</code></a></li><li><a href="#Roots.AllZeros"><code>Roots.AllZeros</code></a></li><li><a href="#Roots.Bisection"><code>Roots.Bisection</code></a></li><li><a href="#Roots.BracketedChebyshev"><code>Roots.BracketedChebyshev</code></a></li><li><a href="#Roots.BracketedHalley"><code>Roots.BracketedHalley</code></a></li><li><a href="#Roots.BracketedSchroder"><code>Roots.BracketedSchroder</code></a></li><li><a href="#Roots.Brent"><code>Roots.Brent</code></a></li><li><a href="#Roots.Chandrapatla"><code>Roots.Chandrapatla</code></a></li><li><a href="#Roots.ChebyshevLike"><code>Roots.ChebyshevLike</code></a></li><li><a href="#Roots.Esser"><code>Roots.Esser</code></a></li><li><a href="#Roots.FalsePosition"><code>Roots.FalsePosition</code></a></li><li><a href="#Roots.Halley"><code>Roots.Halley</code></a></li><li><a href="#Roots.ITP"><code>Roots.ITP</code></a></li><li><a href="#Roots.King"><code>Roots.King</code></a></li><li><a href="#Roots.LithBoonkkampIJzerman"><code>Roots.LithBoonkkampIJzerman</code></a></li><li><a href="#Roots.LithBoonkkampIJzermanBracket"><code>Roots.LithBoonkkampIJzermanBracket</code></a></li><li><a href="#Roots.Newton"><code>Roots.Newton</code></a></li><li><a href="#Roots.Order0"><code>Roots.Order0</code></a></li><li><a href="#Roots.Order1"><code>Roots.Order1</code></a></li><li><a href="#Roots.Order16"><code>Roots.Order16</code></a></li><li><a href="#Roots.Order1B"><code>Roots.Order1B</code></a></li><li><a href="#Roots.Order2"><code>Roots.Order2</code></a></li><li><a href="#Roots.Order2B"><code>Roots.Order2B</code></a></li><li><a href="#Roots.Order5"><code>Roots.Order5</code></a></li><li><a href="#Roots.Order8"><code>Roots.Order8</code></a></li><li><a href="#Roots.QuadraticInverse"><code>Roots.QuadraticInverse</code></a></li><li><a href="#Roots.Ridders"><code>Roots.Ridders</code></a></li><li><a href="#Roots.Schroder"><code>Roots.Schroder</code></a></li><li><a href="#Roots.Secant"><code>Roots.Secant</code></a></li><li><a href="#Roots.Steffensen"><code>Roots.Steffensen</code></a></li><li><a href="#Roots.SuperHalley"><code>Roots.SuperHalley</code></a></li><li><a href="#Roots.Tracks"><code>Roots.Tracks</code></a></li><li><a href="#Roots.ZeroProblem"><code>Roots.ZeroProblem</code></a></li><li><a href="#CommonSolve.solve"><code>CommonSolve.solve</code></a></li><li><a href="#CommonSolve.solve!"><code>CommonSolve.solve!</code></a></li><li><a href="#Roots.assess_convergence"><code>Roots.assess_convergence</code></a></li><li><a href="#Roots.bisection"><code>Roots.bisection</code></a></li><li><a href="#Roots.default_tolerances"><code>Roots.default_tolerances</code></a></li><li><a href="#Roots.dfree"><code>Roots.dfree</code></a></li><li><a href="#Roots.find_zero"><code>Roots.find_zero</code></a></li><li><a href="#Roots.find_zeros"><code>Roots.find_zeros</code></a></li><li><a href="#Roots.fzero"><code>Roots.fzero</code></a></li><li><a href="#Roots.fzeros"><code>Roots.fzeros</code></a></li><li><a href="#Roots.muller"><code>Roots.muller</code></a></li><li><a href="#Roots.newton"><code>Roots.newton</code></a></li><li><a href="#Roots.secant_method"><code>Roots.secant_method</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Roots" href="#Roots.Roots"><code>Roots.Roots</code></a> — <span class="docstring-category">Module</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots</code></pre><p>A package for solving <code>f(x) = 0</code> for univariate, scalar functions.</p><p>The basic methods are</p><ul><li><a href="#Roots.find_zero"><code>find_zero</code></a> for using one of several methods to identify a zero</li><li><a href="#Roots.ZeroProblem"><code>ZeroProblem</code></a> for solving for a zero using the <code>CommonSolve</code> interface</li><li><a href="#Roots.find_zeros"><code>find_zeros</code></a> for heuristically identifying all zeros in a specified interval</li></ul><p><strong>Extended help</strong></p><p><strong>Root finding functions for Julia</strong></p><p><a href="https://JuliaMath.github.io/Roots.jl/stable"><img src="https://img.shields.io/badge/docs-stable-blue.svg" alt="Stable"/></a> <a href="https://JuliaMath.github.io/Roots.jl/dev"><img src="https://img.shields.io/badge/docs-dev-blue.svg" alt="Dev"/></a> <a href="https://github.com/JuliaMath/Roots.jl/actions/workflows/ci.yml"><img src="https://github.com/JuliaMath/Roots.jl/actions/workflows/ci.yml/badge.svg" alt="Build Status"/></a> <a href="https://codecov.io/gh/JuliaMath/Roots.jl"><img src="https://codecov.io/gh/JuliaMath/Roots.jl/graph/badge.svg?token=EbswopIDMU" alt="codecov"/></a></p><p>This package contains simple routines for finding roots, or zeros, of scalar functions of a single real variable using floating-point math. The <code>find_zero</code> function provides the primary interface. The basic call is <code>find_zero(f, x0, [M], [p]; kws...)</code> where, typically, <code>f</code> is a function, <code>x0</code> a starting point or bracketing interval,  <code>M</code> is used to adjust the default algorithms used, and <code>p</code> can be used to pass in parameters.</p><p>The various algorithms include:</p><ul><li><p>Bisection-like algorithms. For functions where a bracketing interval is known (one where <code>f(a)</code> and <code>f(b)</code> have alternate signs), a bracketing method, like <code>Bisection</code>, can be specified.  The default is <code>Bisection</code>, for most floating point number types, employed in a manner exploiting floating point storage conventions. For other number types (e.g. <code>BigFloat</code>), an algorithm of Alefeld, Potra, and Shi is used by default. These default methods are guaranteed to converge.  Other bracketing methods are available.</p></li><li><p>Several derivative-free algorithms. These  are specified through the methods <code>Order0</code>, <code>Order1</code> (the secant method), <code>Order2</code> (the Steffensen method), <code>Order5</code>, <code>Order8</code>, and <code>Order16</code>. The number indicates, roughly, the order of convergence. The <code>Order0</code> method is the default, and the most robust, but may take  more function calls to converge, as it employs a bracketing method when possible. The higher order methods promise faster convergence, though don&#39;t always yield results with fewer function calls than <code>Order1</code> or <code>Order2</code>. The methods <code>Roots.Order1B</code> and <code>Roots.Order2B</code> are superlinear and quadratically converging methods independent of the multiplicity of the zero.</p></li><li><p>There are historic algorithms that require a derivative or two to be specified: <code>Roots.Newton</code> and <code>Roots.Halley</code>. <code>Roots.Schroder</code> provides a quadratic method, like Newton&#39;s method, which is independent of the multiplicity of the zero. This is generalized by <code>Roots.ThukralXB</code> (with <code>X</code> being 2,3,4, or 5).</p></li><li><p>There are several non-exported algorithms, such as, <code>Roots.Brent()</code>, <code>Roots.LithBoonkkampIJzermanBracket</code>, and <code>Roots.LithBoonkkampIJzerman</code>.</p></li></ul><p>Each method&#39;s documentation has additional detail.</p><p>Some examples:</p><pre><code class="language-julia-repl hljs">julia&gt; using Roots

julia&gt; f(x) = exp(x) - x^4;

julia&gt; α₀, α₁, α₂ = -0.8155534188089607, 1.4296118247255556, 8.6131694564414;

julia&gt; find_zero(f, (8,9), Bisection()) ≈ α₂ # a bisection method has the bracket specified
true

julia&gt; find_zero(f, (-10, 0)) ≈ α₀ # Bisection is default if x in `find_zero(f, x)` is not scalar
true


julia&gt; find_zero(f, (-10, 0), Roots.A42()) ≈ α₀ # fewer function evaluations than Bisection
true</code></pre><p>For non-bracketing methods, the initial position is passed in as a scalar, or, possibly, for secant-like methods an iterable like <code>(x_0, x_1)</code>:</p><pre><code class="language-julia-repl hljs">julia&gt; find_zero(f, 3) ≈ α₁  # find_zero(f, x0::Number) will use Order0()
true

julia&gt; find_zero(f, 3, Order1()) ≈ α₁ # same answer, different method (secant)
true

julia&gt; find_zero(f, (3, 2), Order1()) ≈ α₁ # start secant method with (3, f(3), (2, f(2))
true


julia&gt; find_zero(sin, BigFloat(3.0), Order16()) ≈ π # 2 iterations to 6 using Order1()
true</code></pre><p>The <code>find_zero</code> function can be used with callable objects:</p><pre><code class="language-julia-repl hljs">julia&gt; using Polynomials;

julia&gt; x = variable();

julia&gt; find_zero(x^5 - x - 1, 1.0) ≈ 1.1673039782614187
true</code></pre><p>The function should respect the units of the <code>Unitful</code> package:</p><pre><code class="language-julia-repl hljs">julia&gt; using Unitful

julia&gt; s, m  = u&quot;s&quot;, u&quot;m&quot;;

julia&gt; g, v₀, y₀ = 9.8*m/s^2, 10m/s, 16m;


julia&gt; y(t) = -g*t^2 + v₀*t + y₀
y (generic function with 1 method)

julia&gt; find_zero(y, 1s)  ≈ 1.886053370668014s
true</code></pre><p>Newton&#39;s method can be used without taking derivatives by hand. The following examples use the <code>ForwardDiff</code> package:</p><pre><code class="language-julia-repl hljs">julia&gt; using ForwardDiff

julia&gt; D(f) = x -&gt; ForwardDiff.derivative(f,float(x))
D (generic function with 1 method)</code></pre><p>Now we have:</p><pre><code class="language-julia-repl hljs">julia&gt; f(x) = x^3 - 2x - 5
f (generic function with 1 method)

julia&gt; x0 = 2
2

julia&gt; find_zero((f, D(f)), x0, Roots.Newton()) ≈ 2.0945514815423265
true</code></pre><p>Automatic derivatives allow for easy solutions to finding critical points of a function.</p><pre><code class="language-julia-repl hljs">julia&gt; using Statistics: mean, median

julia&gt; as = rand(5);

julia&gt; M(x) = sum((x-a)^2 for a in as)
M (generic function with 1 method)

julia&gt; find_zero(D(M), .5) ≈ mean(as)
true

julia&gt; med(x) = sum(abs(x-a) for a in as)
med (generic function with 1 method)

julia&gt; find_zero(D(med), (0, 1)) ≈ median(as)
true</code></pre><p><strong>The CommonSolve interface</strong></p><p>The <a href="https://github.com/SciML/DifferentialEquations.jl">DifferentialEquations</a> interface of setting up a problem; initializing the problem; then solving the problem is also implemented using the types <code>ZeroProblem</code> and the methods <code>init</code>, <code>solve!</code>, and <code>solve</code> (from <a href="https://github.com/SciML/CommonSolve.jl">CommonSolve</a>).</p><p>For example, we can solve a problem with many different methods, as follows:</p><pre><code class="language-julia-repl hljs">julia&gt; f(x) = exp(-x) - x^3
f (generic function with 1 method)

julia&gt; x0 = 2.0
2.0

julia&gt; fx = ZeroProblem(f, x0)
ZeroProblem{typeof(f), Float64}(f, 2.0)

julia&gt; solve(fx) ≈ 0.7728829591492101
true</code></pre><p>With no default, and a single initial point specified, the default <code>Order1</code> method is used.  The <code>solve</code> method allows other root-solving methods to be passed, along with other options. For example, to use the <code>Order2</code> method using a convergence criteria (see below) that <code>|xₙ - xₙ₋₁| ≤ δ</code>, we could make this call:</p><pre><code class="language-julia-repl hljs">julia&gt; solve(fx, Order2(); atol=0.0, rtol=0.0) ≈ 0.7728829591492101
true</code></pre><p>Unlike <code>find_zero</code>, which errors on non-convergence, <code>solve</code> returns <code>NaN</code> on non-convergence.</p><p>This next example has a zero at <code>0.0</code>, but for most initial values will escape towards <code>±∞</code>, sometimes causing a relative tolerance to return a misleading value. Here we can see the differences:</p><pre><code class="language-julia-repl hljs">julia&gt; f(x) = cbrt(x) * exp(-x^2)
f (generic function with 1 method)

julia&gt; x0 = 0.1147
0.1147

julia&gt; find_zero(f, x0, Roots.Order5()) ≈ 5.936596662527689 # stopped as |f(xₙ)| ≤ |xₙ|ϵ
true

julia&gt; find_zero(f, x0, Roots.Order1(), atol=0.0, rtol=0.0) # error as no check on `|f(xn)|`
ERROR: Roots.ConvergenceFailed(&quot;Algorithm failed to converge&quot;)
[...]

julia&gt; fx = ZeroProblem(f, x0);

julia&gt; solve(fx, Roots.Order1(), atol=0.0, rtol=0.0) # NaN, not an error
NaN

julia&gt; fx = ZeroProblem((f, D(f)), x0); # higher order methods can identify zero of this function

julia&gt; solve(fx, Roots.LithBoonkkampIJzerman(2,1), atol=0.0, rtol=0.0)
0.0</code></pre><p>Functions may be parameterized, as illustrated:</p><pre><code class="language-julia-repl hljs">julia&gt; f(x, p=2) = cos(x) - x/p
f (generic function with 2 methods)

julia&gt; Z = ZeroProblem(f, pi/4)
ZeroProblem{typeof(f), Float64}(f, 0.7853981633974483)

julia&gt; solve(Z, Order1()) ≈ 1.0298665293222586     # use p=2 default
true

julia&gt; solve(Z, Order1(), p=3) ≈ 1.170120950002626 # use p=3
true

julia&gt; solve(Z, Order1(), 4) ≈ 1.2523532340025887  # by position, uses p=4
true</code></pre><p><strong>Multiple zeros</strong></p><p>The <code>find_zeros</code> function can be used to search for all zeros in a specified interval. The basic algorithm essentially splits the interval into many subintervals. For each, if there is a bracket, a bracketing algorithm is used to identify a zero, otherwise a derivative free method is used to search for zeros. This heuristic algorithm can miss zeros for various reasons, so the results should be confirmed by other means.</p><pre><code class="language-julia-repl hljs">julia&gt; f(x) = exp(x) - x^4
f (generic function with 2 methods)

julia&gt; find_zeros(f, -10,10) ≈ [α₀, α₁, α₂] # from above
true</code></pre><p>The interval can also be specified using a structure with <code>extrema</code> defined, where <code>extrema</code> returns two different values:</p><pre><code class="language-julia-repl hljs">julia&gt; using IntervalSets

julia&gt; find_zeros(f, -10..10) ≈ [α₀, α₁, α₂]
true</code></pre><p>(For tougher problems, the <a href="https://github.com/JuliaIntervals/IntervalRootFinding.jl">IntervalRootFinding</a> package gives guaranteed results, rather than the heuristically identified values returned by <code>find_zeros</code>.)</p><p><strong>Convergence</strong></p><p>For most algorithms, convergence is decided when</p><ul><li><p>The value <code>|f(x_n)| &lt;= tol</code> with <code>tol = max(atol, abs(x_n)*rtol)</code>, or</p></li><li><p>the values <code>x_n ≈ x_{n-1}</code> with tolerances <code>xatol</code> and <code>xrtol</code> <em>and</em> <code>f(x_n) ≈ 0</code> with a <em>relaxed</em> tolerance based on <code>atol</code> and <code>rtol</code>.</p></li></ul><p>The <code>find_zero</code> algorithm stops if</p><ul><li><p>it encounters an <code>NaN</code> or an <code>Inf</code>, or</p></li><li><p>the number of iterations exceed <code>maxevals</code></p></li></ul><p>If the algorithm stops and the relaxed convergence criteria is met, the suspected zero is returned. Otherwise an error is thrown indicating no convergence. To adjust the tolerances, <code>find_zero</code> accepts keyword arguments <code>atol</code>, <code>rtol</code>, <code>xatol</code>, and <code>xrtol</code>, as seen in some examples above.</p><p>The <code>Bisection</code> and <code>Roots.A42</code> methods are guaranteed to converge even if the tolerances are set to zero, so these are the defaults. Non-zero values for <code>xatol</code> and <code>xrtol</code> can be specified to reduce the number of function calls when lower precision is required.</p><pre><code class="language-julia-repl hljs">julia&gt; fx = ZeroProblem(sin, (3,4));

julia&gt; solve(fx, Bisection(); xatol=1/16)
3.125</code></pre><p><strong>An alternate interface</strong></p><p>This functionality is provided by the <code>fzero</code> function, familiar to MATLAB users. <code>Roots</code> also provides this alternative interface:</p><ul><li><p><code>fzero(f, x0::Real; order=0)</code> calls a derivative-free method. with the order specifying one of <code>Order0</code>, <code>Order1</code>, etc.</p></li><li><p><code>fzero(f, a::Real, b::Real)</code> calls the <code>find_zero</code> algorithm with the <code>Bisection</code> method.</p></li><li><p><code>fzeros(f, a::Real, b::Real)</code> will call <code>find_zeros</code>.</p></li></ul><p><strong>Usage examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; f(x) = exp(x) - x^4
f (generic function with 2 methods)

julia&gt; fzero(f, 8, 9) ≈ α₂   # bracketing
true

julia&gt; fzero(f, -10, 0) ≈ α₀
true

julia&gt; fzeros(f, -10, 10) ≈ [α₀, α₁, α₂]
true

julia&gt; fzero(f, 3) ≈ α₁      # default is Order0()
true

julia&gt; fzero(sin, big(3), order=16)  ≈ π # uses higher order method
true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Roots.jl#L1-L14">source</a></section></article><h2 id="The-find_zero-and-find_zeros-functions"><a class="docs-heading-anchor" href="#The-find_zero-and-find_zeros-functions">The <code>find_zero</code>  and <code>find_zeros</code> functions</a><a id="The-find_zero-and-find_zeros-functions-1"></a><a class="docs-heading-anchor-permalink" href="#The-find_zero-and-find_zeros-functions" title="Permalink"></a></h2><p>There are  two main  functions:  <code>find_zero</code>   to  identify  a  zero  of  <span>$f$</span>  given  some initial starting  value or  bracketing interval and  <code>find_zeros</code> to heuristically identify  all  zeros in  a specified interval.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.find_zero" href="#Roots.find_zero"><code>Roots.find_zero</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">find_zero(f, x0, M, [N::AbstractBracketingMethod], [p=nothing]; kwargs...)</code></pre><p>Interface to one of several methods for finding zeros of a univariate function, e.g. solving <span>$f(x)=0$</span>.</p><p><strong>Arguments</strong></p><p><strong>Positional arguments</strong></p><ul><li><code>f</code>: the function (univariate or <code>f(x,p)</code> with <code>p</code> holding parameters)</li><li><code>x0</code>: the initial condition (a value, initial values, or bracketing interval)</li><li><code>M</code>: some <code>AbstractUnivariateZeroMethod</code> specifying the solver</li><li><code>N</code>: some bracketing method, when specified creates a hybrid method</li><li><code>p</code>: for specifying a parameter to <code>f</code>. Also can be a keyword, but a positional argument is helpful with broadcasting.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>xatol</code>, <code>xrtol</code>: absolute and relative tolerance to decide if <code>xₙ₊₁ ≈ xₙ</code></li><li><code>atol</code>, <code>rtol</code>: absolute and relative tolerance to decide if <code>f(xₙ) ≈ 0</code></li><li><code>maxiters</code>: specify the maximum number of iterations the algorithm can take.</li><li><code>verbose::Bool</code>: specifies if details about algorithm should be shown</li><li><code>tracks</code>: allows specification of <code>Tracks</code> objects</li></ul><p><strong>Extended help</strong></p><p><strong>Initial starting value</strong></p><p>For most methods, <code>x0</code> is a scalar value indicating the initial value in the iterative procedure. (Secant methods can have a tuple specify their initial values.) Values must be a subtype of <code>Number</code> and have methods for <code>float</code>, <code>real</code>, and <code>oneunit</code> defined.</p><p>For bracketing intervals, <code>x0</code> is specified using a tuple, a vector, or any iterable with <code>extrema</code> defined. A bracketing interval, <span>$[a,b]$</span>, is one where <span>$f(a)$</span> and <span>$f(b)$</span> have different signs.</p><p><strong>Return value</strong></p><p>If the algorithm succeeds, the approximate root identified is returned. A <code>ConvergenceFailed</code> error is thrown if the algorithm fails. The alternate form <code>solve(ZeroProblem(f,x0), M)</code> returns <code>NaN</code> in case of failure.</p><p><strong>Specifying a method</strong></p><p>A method is specified to indicate which algorithm to employ:</p><ul><li><p>There are methods where a bracket is specified: <a href="#Roots.Bisection"><code>Bisection</code></a>, <a href="#Roots.A42"><code>A42</code></a>, <a href="#Roots.AlefeldPotraShi"><code>AlefeldPotraShi</code></a>, <a href="#Roots.Brent"><code>Roots.Brent</code></a>, among others. Bisection is the default for basic floating point types, but <code>A42</code> generally requires far fewer iterations.</p></li><li><p>There are several derivative-free methods: cf. <a href="#Roots.Order0"><code>Order0</code></a>, <a href="#Roots.Order1"><code>Order1</code></a> (also <a href="#Roots.Secant"><code>Roots.Secant</code></a>), <a href="#Roots.Order2"><code>Order2</code></a> (also <a href="#Roots.Steffensen"><code>Steffensen</code></a>), <a href="#Roots.Order5"><code>Order5</code></a>, <a href="#Roots.Order8"><code>Order8</code></a>, and <a href="#Roots.Order16"><code>Order16</code></a>, where the number indicates the order of the convergence.</p></li><li><p>There are some classical methods where derivatives need specification: <a href="#Roots.Newton"><code>Roots.Newton</code></a>, <a href="#Roots.Halley"><code>Roots.Halley</code></a>, <a href="#Roots.Schroder"><code>Roots.Schroder</code></a>, among others.</p></li><li><p>Methods intended for problems with multiplicities include <a href="#Roots.Order1B"><code>Roots.Order1B</code></a>, <a href="#Roots.Order2B"><code>Roots.Order2B</code></a>, and <code>Roots.ThukralXB</code> for different <code>X</code>s.</p></li><li><p>The family <a href="#Roots.LithBoonkkampIJzerman"><code>Roots.LithBoonkkampIJzerman{S,D}</code></a> ,for different <code>S</code> and <code>D</code>, uses a linear multistep method root finder. The <code>(2,0)</code> method is the secant method, <code>(1,1)</code> is Newton&#39;s method.</p></li></ul><p>For more detail, see the help page for each method (e.g., <code>?Order1</code>). Non-exported methods must be qualified with the module name, as in <code>?Roots.Schroder</code>.</p><p>If no method is specified, the default method depends on <code>x0</code>:</p><ul><li><p>If <code>x0</code> is a scalar, the default is the more robust <code>Order0</code> method.</p></li><li><p>If <code>x0</code> is a tuple, vector, or iterable with <code>extrema</code> defined indicating a <em>bracketing</em> interval, then the <code>Bisection</code> method is used for <code>Float64</code>, <code>Float32</code> or <code>Float16</code> types; otherwise the <code>A42</code> method is used.</p></li></ul><p>The default methods are chosen to be robust; they may not be as efficient as some others.</p><p><strong>Specifying the function</strong></p><p>The function(s) are passed as the first argument.</p><p>For the few methods that use one or more derivatives (<code>Newton</code>, <code>Halley</code>, <code>Schroder</code>, <code>LithBoonkkampIJzerman(S,D)</code>, etc.) a tuple of functions is used. For the classical algorithms, a function returning <code>(f(x), f(x)/f&#39;(x), [f&#39;(x)/f&#39;&#39;(x)])</code> may be used.</p><p><strong>Optional arguments (tolerances, limit evaluations, tracing)</strong></p><ul><li><code>xatol</code> - absolute tolerance for <code>x</code> values.</li><li><code>xrtol</code> - relative tolerance for <code>x</code> values.</li><li><code>atol</code>  - absolute tolerance for <code>f(x)</code> values.</li><li><code>rtol</code>  - relative tolerance for <code>f(x)</code> values.</li><li><code>maxiters</code>   - limit on maximum number of iterations.</li><li><code>strict</code> - if <code>false</code> (the default), when the algorithm stops, possible zeros are checked with a relaxed tolerance.</li><li><code>verbose</code> - if <code>true</code> a trace of the algorithm will be shown on successful completion. See the internal <a href="#Roots.Tracks"><code>Roots.Tracks</code></a> object to save this trace.</li></ul><p>See the help string for <code>Roots.assess_convergence</code> for details on convergence. See the help page for <code>Roots.default_tolerances(method)</code> for details on the default tolerances.</p><p>In general, with floating point numbers, convergence must be understood as not an absolute statement. Even if mathematically <code>α</code> is an answer and <code>xstar</code> the floating point realization, it may be that <code>f(xstar) - f(α)  ≈ xstar ⋅  f&#39;(α) ⋅ eps(α)</code>, so the role of tolerances must be appreciated, and at times specified.</p><p>For the <code>Bisection</code> methods, convergence is guaranteed over <code>Float64</code> values, so the tolerances are set to be <span>$0$</span> by default.</p><p>If a bracketing method is passed in after the method specification, then whenever a bracket is identified during the algorithm, the method will switch to the bracketing method to identify the zero. (Bracketing methods are mathematically guaranteed to converge, non-bracketing methods may or may not converge.)  This is what <code>Order0</code> does by default, with an initial secant method switching to the <code>AlefeldPotraShi</code> method should a bracket be encountered.</p><p>Note: The order of the method is hinted at in the naming scheme. A scheme is order <code>r</code> if, with <code>eᵢ = xᵢ - α</code>, <code>eᵢ₊₁ = C⋅eᵢʳ</code>. If the error <code>eᵢ</code> is small enough, then essentially the error will gain <code>r</code> times as many leading zeros each step. However, if the error is not small, this will not be the case. Without good initial guesses, a high order method may still converge slowly, if at all. The <code>OrderN</code> methods have some heuristics employed to ensure a wider range for convergence at the cost of not faithfully implementing the method, though those are available through unexported methods.</p><p><strong>Examples:</strong></p><p>Default methods.</p><pre><code class="language-julia-repl hljs">julia&gt; using Roots

julia&gt; find_zero(sin, 3)  # use Order0()
3.141592653589793

julia&gt; find_zero(sin, (3,4)) # use Bisection()
3.141592653589793</code></pre><p>Specifying a method,</p><pre><code class="language-julia-repl hljs">julia&gt; find_zero(sin, (3,4), Order1())            # can specify two starting points for secant method
3.141592653589793

julia&gt; find_zero(sin, 3.0, Order2())              # Use Steffensen method
3.1415926535897936

julia&gt; find_zero(sin, big(3.0), Order16())        # rapid convergence
3.141592653589793238462643383279502884197169399375105820974944592307816406286198

julia&gt; find_zero(sin, (3, 4), A42())              # fewer function calls than Bisection(), in this case
3.141592653589793

julia&gt; find_zero(sin, (3, 4), FalsePosition(8))   # 1 of 12 possible algorithms for false position
3.141592653589793

julia&gt; find_zero((sin,cos), 3.0, Roots.Newton())  # use Newton&#39;s method
3.141592653589793

julia&gt; find_zero((sin, cos, x-&gt;-sin(x)), 3.0, Roots.Halley())  # use Halley&#39;s method
3.141592653589793</code></pre><p>Changing tolerances.</p><pre><code class="language-julia-repl hljs">julia&gt; fn = x -&gt; (2x*cos(x) + x^2 - 3)^10/(x^2 + 1);

julia&gt; x0, xstar = 3.0,  2.9947567209477;

julia&gt; fn(find_zero(fn, x0, Order2())) &lt;= 1e-14  # f(xₙ) ≈ 0, but Δxₙ can be largish
true

julia&gt; find_zero(fn, x0, Order2(), atol=0.0, rtol=0.0) # error: x_n ≉ x_{n-1}; just f(x_n) ≈ 0
ERROR: Roots.ConvergenceFailed(&quot;Algorithm failed to converge&quot;)
[...]

julia&gt; fn = x -&gt; (sin(x)*cos(x) - x^3 + 1)^9;

julia&gt; x0, xstar = 1.0,  1.112243913023029;

julia&gt; isapprox(find_zero(fn, x0, Order2()), xstar; atol=1e-4)
true

julia&gt; find_zero(fn, x0, Order2(), maxiters=3)    # need more steps to converge
ERROR: Roots.ConvergenceFailed(&quot;Algorithm failed to converge&quot;)
[...]</code></pre><p><strong>Tracing</strong></p><p>Passing <code>verbose=true</code> will show details on the steps of the algorithm. The <code>tracks</code> argument allows the passing of a <a href="#Roots.Tracks"><code>Roots.Tracks</code></a> object to record the values of <code>x</code> and <code>f(x)</code> used in the algorithm.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>See <a href="#CommonSolve.solve!"><code>solve!</code></a> and <a href="#Roots.ZeroProblem"><code>ZeroProblem</code></a> for an alternate interface.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/find_zero.jl#L1-L209">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.find_zeros" href="#Roots.find_zeros"><code>Roots.find_zeros</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">find_zeros(f, a, [b]; [no_pts=12, k=8, naive=false, xatol, xrtol, atol, rtol])</code></pre><p>Search for zeros of <code>f</code> in the interval <code>[a,b]</code> with an heuristic algorithm.</p><ul><li><code>f</code>: a function or callable object</li><li><code>a</code>, <code>b</code>:  If <code>b</code> is specified, the interval <span>$[a,b]$</span> is used. If only <code>a</code> is specified, it is passed to <code>extrema</code> to define the interval to search over.   It is assumed that neither endpoint is a zero.</li></ul><p>Returns a vector of zeros in sorted order, possibly empty.</p><p><strong>Extended help</strong></p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using Roots

julia&gt; find_zeros(x -&gt; exp(x) - x^4, -5, 20)        # a few well-spaced zeros
3-element Vector{Float64}:
 -0.8155534188089606
  1.4296118247255556
  8.613169456441398

julia&gt; find_zeros(x -&gt; sin(x^2) + cos(x)^2, 0, 2pi)  # many zeros
12-element Vector{Float64}:
 1.78518032659534
 2.391345462376604
 3.2852368649448853
 3.3625557095737544
 4.016412952618305
 4.325091924521049
 4.68952781386834
 5.00494459113514
 5.35145266881871
 5.552319796014526
 5.974560835055425
 6.039177477770888

julia&gt; find_zeros(x -&gt; cos(x) + cos(2x), (0, 4pi))    # mix of simple, non-simple zeros
6-element Vector{Float64}:
  1.0471975511965976
  3.141592653589943
  5.235987755982988
  7.330382858376184
  9.424777960769228
 11.519173063162574

julia&gt; f(x) = (x-0.5) * (x-0.5001) * (x-1)          # nearby zeros
f (generic function with 1 method)

julia&gt; find_zeros(f, 0, 2)
3-element Vector{Float64}:
 0.5
 0.5001
 1.0

julia&gt; f(x) = (x-0.5) * (x-0.5001) * (x-4) * (x-4.001) * (x-4.2)
f (generic function with 1 method)

julia&gt; find_zeros(f, 0, 10)
3-element Vector{Float64}:
 0.5
 0.5001
 4.2

julia&gt; f(x) = (x-0.5)^2 * (x-0.5001)^3 * (x-4) * (x-4.001) * (x-4.2)^2  # hard to identify
f (generic function with 1 method)

julia&gt; find_zeros(f, 0, 10, no_pts=21)                # too hard for default
5-element Vector{Float64}:
 0.49999999999999994
 0.5001
 4.0
 4.001
 4.200000000000001</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Some cases where the number of zeros may be underreported:</p><ul><li>if the initial interval, <code>(a,b)</code>, is too wide</li><li>if there are zeros  that are very nearby</li><li>the function is flat, e.g., <code>x-&gt;0</code>.</li></ul></div></div><hr/><p>The basic algorithm checks for zeros among the endpoints, and then divides the interval <code>(a,b)</code> into <code>no_pts-1</code> subintervals and then proceeds to look for zeros through bisection or a derivative-free method.  As checking for a bracketing interval is relatively cheap and bisection is guaranteed to converge, each interval has <code>k</code> pairs of intermediate points checked for a bracket.</p><p>If any zeros are found, the algorithm uses these to partition <code>(a,b)</code> into subintervals. Each subinterval is shrunk so that the endpoints are not zeros and the process is repeated on the subinterval. If the initial interval is too large, then the naive scanning for zeros may be fruitless and no zeros will be reported. If there are nearby zeros, the shrinking of the interval may jump over them, though as seen in the examples, nearby roots can be identified correctly, though for really nearby points, or very flat functions, it may help to increase <code>no_pts</code>.</p><p>The tolerances are used to shrink the intervals, but not to find zeros within a search. For searches, bisection is guaranteed to converge with no specified tolerance. For the derivative free search, a modification of the <code>Order0</code> method is used, which at worst case compares <code>|f(x)| &lt;= 8*eps(x)</code> to identify a zero. The algorithm might identify more than one value for a zero, due to floating point approximations. If a potential pair of zeros satisfy <code>isapprox(a,b,atol=sqrt(xatol), rtol=sqrt(xrtol))</code> then they are consolidated.</p><p>The algorithm can make many function calls. When zeros are found in an interval, the naive search is carried out on each subinterval. To cut down on function calls, though with some increased chance of missing some zeros, the adaptive nature can be skipped with the argument <code>naive=true</code> or the number of points stepped down.</p><p>The algorithm is derived from one in a <a href="https://github.com/JuliaMath/Roots.jl/pull/113">PR</a> by @djsegal.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The <code>IntervalRootFinding</code> package provides a rigorous alternative to this heuristic one. That package uses interval arithmetic, so can compute bounds on the size of the image of an interval under <code>f</code>. If this image includes <code>0</code>, then it can look for the zero. Bisection, on the other hand, only will look for a zero if the two endpoints have different signs, a much more rigid condition for a potential zero.</p></div></div><div class="admonition is-info"><header class="admonition-header">`IntervalRootFinding` extension</header><div class="admonition-body"><p>As of version <code>1.9</code> an extension is provided so that when the <code>IntervalRootFinding</code> package is loaded, the <code>find_zeros</code> function will call <code>IntervalRootFinding.roots</code> to find the isolating brackets and <code>find_zero</code> to find the roots, when possible, <strong>if</strong> the interval is specified as an <code>Interval</code> object, as created by <code>-1..1</code>, say.</p></div></div><p>For example, this function (due to <code>@truculentmath</code>) is particularly tricky, as it is positive at every floating point number, but has two zeros (the vertical asymptote at <code>15//11</code> is only negative within adjacent floating point values):</p><pre><code class="nohighlight hljs">julia&gt; using IntervalArithmetic, IntervalRootFinding, Roots

julia&gt; g(x) = x^2 + 1 +log(abs( 11*x-15 ))/99
g (generic function with 1 method)

julia&gt; find_zeros(g, -3, 3)
Float64[]

julia&gt; IntervalRootFinding.roots(g, -3..3, IntervalRootFinding.Bisection)
1-element Vector{Root{Interval{Float64}}}:
 Root([1.36363, 1.36364], :unknown)</code></pre><p>A less extreme usage might be the following, where <code>unique</code> indicates Bisection could be useful and indeed <code>find_zeros</code> will identify these values:</p><pre><code class="nohighlight hljs">julia&gt; g(x) = exp(x) - x^5
g (generic function with 1 method)

julia&gt; rts = IntervalRootFinding.roots(g, -20..20)
2-element Vector{Root{Interval{Float64}}}:
 Root([12.7132, 12.7133], :unique)
 Root([1.29585, 1.29586], :unique)

julia&gt; find_zeros(g, -20, 20)
2-element Vector{Float64}:
  1.2958555090953687
 12.713206788867632</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/find_zeros.jl#L136-L309">source</a></section></article><h2 id="CommonSolve-interface"><a class="docs-heading-anchor" href="#CommonSolve-interface">CommonSolve interface</a><a id="CommonSolve-interface-1"></a><a class="docs-heading-anchor-permalink" href="#CommonSolve-interface" title="Permalink"></a></h2><p>The problem-algorithm-solve interface is a pattern popularized in <code>Julia</code> by the <code>DifferentialEquations.jl</code> suite of packages. This can be used as an alternative to <code>find_zero</code>. Unlike <code>find_zero</code>, <code>solve</code> will return <code>NaN</code> on non-convergence.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="CommonSolve.solve!" href="#CommonSolve.solve!"><code>CommonSolve.solve!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve!(P::ZeroProblemIterator)
solve(fx::ZeroProblem, [M], [N]; p=nothing, kwargs...)
init(fx::ZeroProblem, [M], [N];
     p=nothing,
     verbose=false, tracks=NullTracks(), kwargs...)</code></pre><p>Solve for the zero of a scalar-valued univariate function specified through <code>ZeroProblem</code> or <code>ZeroProblemIterator</code> using the <code>CommonSolve</code> interface.</p><p>The defaults for <code>M</code> and <code>N</code> depend on the <code>ZeroProblem</code>: if <code>x0</code> is a number, then <code>M=Secant()</code> and <code>N=AlefeldPotraShi()</code> is used (<code>Order0</code>); if <code>x0</code> has <code>2</code> (or more values) then it is assumed to be a bracketing interval and <code>M=AlefeldPotraShi()</code> is used.</p><p>The methods involved with this interface are:</p><ul><li><code>ZeroProblem</code>: used to specify a problem with a function (or functions) and an initial guess</li><li><code>solve</code>: to solve for a zero in a <code>ZeroProblem</code></li></ul><p>The latter calls the following, which can be useful independently:</p><ul><li><code>init</code>: to initialize an iterator with a method for solution, any adjustments to the default tolerances, and a specification to log the steps or not.</li><li><code>solve!</code> to iterate to convergence.</li></ul><p>Returns <code>NaN</code>, not an error like <code>find_zero</code>, when the problem can not be solved. Tested for zero allocations.</p><p><strong>Examples:</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using Roots

julia&gt; fx = ZeroProblem(sin, 3)
ZeroProblem{typeof(sin), Int64}(sin, 3)

julia&gt; solve(fx)
3.141592653589793</code></pre><p>Or, if the iterable is required</p><pre><code class="language-julia-repl hljs">julia&gt; problem = init(fx);

julia&gt; solve!(problem)
3.141592653589793</code></pre><p>keyword arguments can be used to adjust the default tolerances.</p><pre><code class="language-julia-repl hljs">julia&gt; solve(fx, Order5(); atol=1/100)
3.1425464815525403</code></pre><p>The above is equivalent to:</p><pre><code class="language-julia-repl hljs">julia&gt; problem = init(fx, Order5(), atol=1/100);

julia&gt; solve!(problem)
3.1425464815525403</code></pre><p>The keyword argument <code>p</code> may be used if the function(s) to be solved depend on a parameter in their second positional argument (e.g., <code>f(x, p)</code>). For example</p><pre><code class="language-julia-repl hljs">julia&gt; f(x,p) = exp(-x) - p # to solve p = exp(-x)
f (generic function with 1 method)

julia&gt; fx = ZeroProblem(f, 1)
ZeroProblem{typeof(f), Int64}(f, 1)

julia&gt; solve(fx; p=1/2)  # log(2)
0.6931471805599453</code></pre><p>This would be recommended, as there is no recompilation due to the function changing. For use with broadcasting, <code>p</code> may also be the last positional argument.</p><p>The argument <code>verbose=true</code> for <code>init</code> instructs that steps to be logged;</p><p>The iterator interface allows for the creation of hybrid solutions, such as is used when two methods are passed to <code>solve</code>. For example, this is essentially how the hybrid default is constructed:</p><pre><code class="language-julia-repl hljs">julia&gt; function order0(f, x)
           fx = ZeroProblem(f, x)
           p = init(fx, Roots.Secant())
           xᵢ,st = ϕ = iterate(p)
           while ϕ !== nothing
               xᵢ, st = ϕ
               state, ctr = st
               fᵢ₋₁, fᵢ = state.fxn0, state.fxn1
               if sign(fᵢ₋₁)*sign(fᵢ) &lt; 0 # check for bracket
                   x0 = (state.xn0, state.xn1)
                   fx′ = ZeroProblem(f, x0)
                   p = init(fx′, Bisection())
                   xᵢ = solve!(p)
                   break
               end
               ϕ = iterate(p, st)
           end
           xᵢ
       end
order0 (generic function with 1 method)

julia&gt; order0(sin, 3)
3.141592653589793</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/find_zero.jl#L321-L442">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="CommonSolve.solve" href="#CommonSolve.solve"><code>CommonSolve.solve</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve(fx::ZeroProblem, args...; verbose=false, kwargs...)</code></pre><p>Disptaches to <code>solve!(init(fx, args...; kwargs...))</code>. See <a href="#CommonSolve.solve!"><code>solve!</code></a> for details.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/find_zero.jl#L473-L477">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.ZeroProblem" href="#Roots.ZeroProblem"><code>Roots.ZeroProblem</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ZeroProblem{F,X}</code></pre><p>A container for a function and initial guess to be used with <code>solve</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/find_zero.jl#L253-L257">source</a></section></article><h2 id="Classical-methods-based-on-derivatives"><a class="docs-heading-anchor" href="#Classical-methods-based-on-derivatives">Classical  methods  based on derivatives</a><a id="Classical-methods-based-on-derivatives-1"></a><a class="docs-heading-anchor-permalink" href="#Classical-methods-based-on-derivatives" title="Permalink"></a></h2><p>We begin  by  describing  the classical methods even though they are not necessarily  recommended  because they require more work of the  user,  as they give insight into  why there  are a variety  of methods available.</p><p>The classical  methods of <a href="https://en.wikipedia.org/wiki/Newton%27s_method">Newton</a> and  <a href="https://en.wikipedia.org/wiki/Halley%27s_method">Halley</a> utilize information about  the function  and  its derivative(s) in  an  iterative manner  to converge to  a zero of  <span>$f(x)$</span> given an initial starting value.</p><p>Newton&#39;s method is   easily described:</p><p>From  an initial point,  the  next  point  in  the iterative algorithm is found by identifying the  intersection of  the <span>$x$</span>    axis  with  the tangent line of <span>$f$</span> at the initial  point. This is repeated until convergence  or the realization that   convergence won&#39;t happen for the  initial point. Mathematically,</p><p><span>$x_{n+1}  =  x_{n}  - f(x_n)/f&#39;(x_n).$</span></p><p>Some facts  are helpful  to  understand the different methods  available in <code>Roots</code>:</p><ul><li><p>For Newton&#39;s method there is a formula for the error: Set <span>$\epsilon_n = \alpha - x_n$</span>, where <span>$\alpha$</span> is the zero, then <span>$\epsilon_{n+1} = -f&#39;&#39;(\xi_n)/(2f&#39;(\xi_n) \cdot \epsilon_n^2,$</span> here <span>$\xi_n$</span> is some value between <span>$\alpha$</span> and <span>$x_n$</span>.</p></li><li><p>The error term, when of the form <span>$|\epsilon_{n+1}| \leq C\cdot|\epsilon_n|^2$</span>, can be used to identify an interval around <span>$\alpha$</span> for which convergence is guaranteed. Such convergence is termed <em>quadratic</em> (order 2).  For floating point solutions, quadratic convergence and a well chosen initial point can lead to convergence in 4 or 5 iterations. In general, convergence is termed order <span>$q$</span> when <span>$|\epsilon_{n+1}| \approx C\cdot|\epsilon_n|^q$</span></p></li><li><p>The term <span>$-f&#39;&#39;(\xi_n)/(2f&#39;(\xi_n)$</span> indicates possible issues  when <span>$f&#39;&#39;$</span>  is  too big  near <span>$\alpha$</span>  or  <span>$f&#39;$</span> is too small  near <span>$\alpha$</span>. In particular if <span>$f&#39;(\alpha)  =  0$</span>, there need  not be quadratic  convergence, and convergence  can   take many  iterations. A  zero   for which <span>$f(x) = (x-\alpha)^{1+\beta}\cdot g(x)$</span>, with <span>$g(\alpha) \neq 0$</span>  is called <em>simple</em> when <span>$\beta=0$</span> and  non-simple when  <span>$\beta &gt;  0$</span>. Newton&#39;s method is quadratic near <em>simple  zeros</em> and need not be quadratic  near  <em>non-simple</em> zeros.</p></li></ul><p>As well,  if  <span>$f&#39;&#39;$</span> is too  big near <span>$\alpha$</span>, or  <span>$f&#39;$</span> too small near  <span>$\alpha$</span>, or <span>$x_n$</span>  too  far  from  <span>$\alpha$</span> (that is,  <span>$|\epsilon_n|&gt;1$</span>) the  error  might actually increase and convergence is not guaranteed.</p><ul><li><p>The explicit form of  the error function can  be used to guarantee convergence for functions with a certain shape (monotonic, convex functions where the sign of <span>$f&#39;&#39;$</span> and <span>$f&#39;$</span> don&#39;t change). Quadratic convergence may only occur once the algorithm is near the zero.</p></li><li><p>The number of function evaluations  per step for Newton&#39;s method is 2.</p></li></ul><hr/><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Newton" href="#Roots.Newton"><code>Roots.Newton</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.Newton()</code></pre><p>Implements Newton&#39;s <a href="https://en.wikipedia.org/wiki/Newton%27s_method">method</a>: <code>xᵢ₊₁ =  xᵢ - f(xᵢ)/f&#39;(xᵢ)</code>.  This is a quadratically convergent method requiring one derivative and two function calls per step.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using Roots

julia&gt; find_zero((sin,cos), 3.0, Roots.Newton()) ≈ π
true</code></pre><p>If function evaluations are expensive one can pass in a function which returns (f, f/f&#39;) as follows</p><pre><code class="language-julia-repl hljs">julia&gt; find_zero(x -&gt; (sin(x), sin(x)/cos(x)), 3.0, Roots.Newton()) ≈ π
true</code></pre><p>This can be advantageous if the derivative is easily computed from the value of f, but otherwise would be expensive to compute.</p><hr/><p>The error, <code>eᵢ = xᵢ - α</code>, can be expressed as <code>eᵢ₊₁ = f[xᵢ,xᵢ,α]/(2f[xᵢ,xᵢ])eᵢ²</code> (Sidi, Unified treatment of regula falsi, Newton-Raphson, secant, and Steffensen methods for nonlinear equations).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/newton.jl#L10-L44">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Halley" href="#Roots.Halley"><code>Roots.Halley</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.Halley()</code></pre><p>Implements Halley&#39;s <a href="https://en.wikipedia.org/wiki/Halley%27s_method">method</a>, <code>xᵢ₊₁ = xᵢ - (f/f&#39;)(xᵢ) * (1 - (f/f&#39;)(xᵢ) * (f&#39;&#39;/f&#39;)(xᵢ) * 1/2)^(-1)</code> This method is cubically converging, it requires <span>$3$</span> function calls per step. Halley&#39;s method finds <code>xₙ₊₁</code> as the zero of a hyperbola at the point <code>(xₙ, f(xₙ))</code> matching the first and second derivatives of <code>f</code>.</p><p>The function, its derivative and second derivative can be passed either as a tuple of <span>$3$</span> functions <em>or</em> as a function returning values for <span>$(f, f/f&#39;, f&#39;/f&#39;&#39;)$</span>, which could be useful when function evaluations are expensive.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using Roots

julia&gt; find_zero((sin, cos, x-&gt;-sin(x)), 3.0, Roots.Halley()) ≈ π
true

julia&gt; function f(x)
       s,c = sincos(x)
       (s, s/c, -c/s)
       end;

julia&gt; find_zero(f, 3.0, Roots.Halley()) ≈ π
true</code></pre><p>This can be advantageous if the derivatives are easily computed from the computation for f, but otherwise would be expensive to compute separately.</p><hr/><p>The error, <code>eᵢ = xᵢ - α</code>, satisfies <code>eᵢ₊₁ ≈ -(2f&#39;⋅f&#39;&#39;&#39; -3⋅(f&#39;&#39;)²)/(12⋅(f&#39;&#39;)²) ⋅ eᵢ³</code> (all evaluated at <code>α</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/halley_like.jl#L59-L96">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.QuadraticInverse" href="#Roots.QuadraticInverse"><code>Roots.QuadraticInverse</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.QuadraticInverse()</code></pre><p>Implements the <a href="https://doi.org/10.2307/2322644">quadratic inverse method</a> also known as <a href="https://dl.acm.org/doi/10.1080/00207160802208358">Chebyshev&#39;s method</a>, <code>xᵢ₊₁ = xᵢ - (f/f&#39;)(xᵢ) * (1 + (f/f&#39;)(xᵢ) * (f&#39;&#39;/f&#39;)(xᵢ) * 1/2)</code>. This method is cubically converging, it requires <span>$3$</span> function calls per step.</p><p>Example</p><pre><code class="language-julia-repl hljs">julia&gt; using Roots

julia&gt; find_zero((sin, cos, x-&gt;-sin(x)), 3.0, Roots.QuadraticInverse()) ≈ π
true</code></pre><p>If function evaluations are expensive one can pass in a function which returns <code>(f, f/f&#39;,f&#39;/f&#39;&#39;)</code> as follows</p><pre><code class="language-julia-repl hljs">julia&gt; find_zero(x -&gt; (sin(x), sin(x)/cos(x), -cos(x)/sin(x)), 3.0, Roots.QuadraticInverse()) ≈ π
true</code></pre><p>This can be advantageous if the derivatives are easily computed from the computation for f, but otherwise would be expensive to compute separately.</p><p>The error, <code>eᵢ = xᵢ - α</code>, <a href="https://dl.acm.org/doi/10.1080/00207160802208358">satisfies</a> <code>eᵢ₊₁ ≈ (1/2⋅(f&#39;&#39;/f&#39;)² - 1/6⋅f&#39;&#39;&#39;/f&#39;)) ⋅ eᵢ³</code> (all evaluated at <code>α</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/halley_like.jl#L99-L130">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.ChebyshevLike" href="#Roots.ChebyshevLike"><code>Roots.ChebyshevLike</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Chebyshev-like methods and quadratic equations (J. A. Ezquerro, J. M. Gutiérrez, M. A. Hernández and M. A. Salanova)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/halley_like.jl#L133-L135">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.SuperHalley" href="#Roots.SuperHalley"><code>Roots.SuperHalley</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>An acceleration of Newton&#39;s method: Super-Halley method (J.M. Gutierrez, M.A. Hernandez)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/halley_like.jl#L138-L140">source</a></section></article><p>Newton and Halley&#39;s method are members of this family of methods:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.LithBoonkkampIJzerman" href="#Roots.LithBoonkkampIJzerman"><code>Roots.LithBoonkkampIJzerman</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LithBoonkkampIJzerman{S,D} &lt;: AbstractNewtonLikeMethod
LithBoonkkampIJzerman(S,D)</code></pre><p>A family of different methods that includes the secant method and Newton&#39;s method.</p><p>Specifies a linear multistep solver with <code>S</code> steps and <code>D</code> derivatives following <a href="https://doi.org/10.1016/j.amc.2017.09.003">Lith, Boonkkamp, and IJzerman</a>.</p><p><strong>Extended help</strong></p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using Roots

julia&gt; find_zero(sin, 3, Roots.LithBoonkkampIJzerman(2,0)) ≈ π # the secant method
true

julia&gt; find_zero((sin,cos), 3, Roots.LithBoonkkampIJzerman(1,1)) ≈ π # Newton&#39;s method
true

julia&gt; find_zero((sin,cos), 3, Roots.LithBoonkkampIJzerman(3,1)) ≈ π # Faster convergence rate
true

julia&gt; find_zero((sin,cos, x-&gt;-sin(x)), 3, Roots.LithBoonkkampIJzerman(1,2)) ≈ π # Halley-like method
true</code></pre><p>The method can be more robust to the initial condition. This example is from the paper (p13). Newton&#39;s method (the <code>S=1</code>, <code>D=1</code> case) fails if <code>|x₀| ≥ 1.089</code> but methods with more memory succeed.</p><pre><code class="language-julia-repl hljs">julia&gt; fx =  ZeroProblem((tanh,x-&gt;sech(x)^2), 1.239); # zero at 0.0

julia&gt; solve(fx, Roots.LithBoonkkampIJzerman(1,1)) |&gt; isnan# Newton, NaN
true

julia&gt; solve(fx, Roots.LithBoonkkampIJzerman(2,1)) |&gt; abs |&gt; &lt;(eps())
true

julia&gt; solve(fx, Roots.LithBoonkkampIJzerman(3,1)) |&gt; abs |&gt; &lt;(eps())
true</code></pre><p>Multiple derivatives can be constructed automatically using automatic differentiation. For example,</p><pre><code class="language-julia-repl hljs">julia&gt; using ForwardDiff

julia&gt; function δ(f, n::Int=1)
           n &lt;= 0 &amp;&amp; return f
           n == 1 &amp;&amp; return x -&gt; ForwardDiff.derivative(f,float(x))
           δ(δ(f,1),n-1)
       end;

julia&gt; fs(f,n) = ntuple(i -&gt; δ(f,i-1), Val(n+1));

julia&gt; f(x) = cbrt(x) * exp(-x^2); # cf. Table 6 in paper, α = 0

julia&gt; fx = ZeroProblem(fs(f,1), 0.1147);

julia&gt; opts = (xatol=2eps(), xrtol=0.0, atol=0.0, rtol=0.0); # converge if |xₙ - xₙ₋₁| &lt;= 2ϵ

julia&gt; solve(fx, Roots.LithBoonkkampIJzerman(1, 1); opts...) |&gt; isnan # NaN -- no convergence
true

julia&gt; solve(fx, Roots.LithBoonkkampIJzerman(2, 1); opts...) |&gt; abs |&gt; &lt;(eps()) # converges
true

julia&gt; fx = ZeroProblem(fs(f,2), 0.06);                       # need better starting point

julia&gt; solve(fx, Roots.LithBoonkkampIJzerman(2, 2); opts...) |&gt; abs |&gt; &lt;(eps()) # converges
true</code></pre><p>For the case <code>D=1</code>, a bracketing method based on this approach is implemented in <a href="#Roots.LithBoonkkampIJzermanBracket"><code>LithBoonkkampIJzermanBracket</code></a></p><p><strong>Reference</strong></p><p>In <a href="https://doi.org/10.1016/j.amc.2017.09.003">Lith, Boonkkamp, and IJzerman</a> an analysis is given of the convergence rates when using linear multistep methods to solve <code>0=f(x)</code> using <code>f⁻¹(0) = x</code> when <code>f</code> is a sufficiently smooth linear function. The reformulation, attributed to Grau-Sanchez, finds a differential equation for <code>f⁻¹</code>: <code>dx/dy = [f⁻¹]′(y) = 1/f′(x) = F</code> as <code>x(0) = x₀ + ∫⁰_y₀ F(x(y)) dy</code>.</p><p>A linear multi-step method is used to solve this equation numerically.  Let S be the number of memory steps (S= 1,2,...) and D be the number of derivatives employed, then, with <code>F(x) = dx/dy</code> <code>x_{n+S} = ∑_{k=0}^{S-1} aₖ x_{n+k} +∑d=1^D ∑_{k=1}^{S-1} aᵈ_{n+k}F⁽ᵈ⁾(x_{n+k})</code>.  The <code>aₖ</code>s and <code>aᵈₖ</code>s are computed each step.</p><p>This table is from Tables 1 and 3 of the paper and gives the convergence rate for simple roots identified therein:</p><pre><code class="nohighlight hljs">s: number of steps remembered
d: number of derivatives uses
s/d  0    1    2    3    4
1    .    2    3    4    5
2    1.62 2.73 3.79 4.82 5.85
3    1.84 2.91 3.95 4.97 5.98
4    1.92 2.97 3.99 4.99 5.996
5    1.97 .    .    .    .</code></pre><p>That is, more memory leads to a higher convergence rate; more derivatives leads to a higher convergence rate. However, the interval about <code>α</code>, the zero, where the convergence rate is guaranteed may get smaller.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For the larger values of <code>S</code>, the expressions to compute the next value get quite involved. The higher convergence rate is likely only to be of help for finding solutions to high precision.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/lith.jl#L1-L117">source</a></section></article><h2 id="Derivative-free-methods"><a class="docs-heading-anchor" href="#Derivative-free-methods">Derivative free methods</a><a id="Derivative-free-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Derivative-free-methods" title="Permalink"></a></h2><p>The <a href="https://en.wikipedia.org/wiki/Secant_method">secant</a> method replaces the  derivative term in Newton&#39;s method with the slope of a secant line using two prior values:</p><p><span>$x_{n+1} = x_n - (\frac{f(x_n)-f(x_{n-1})}{x_n - x_{n-1}})^{-1}\cdot  f(x_n).$</span></p><p>Though the secant  method   has  convergence  rate of  order <span>$\approx 1.618$</span> – i.e., is not quadratic –  it only requires one new  function call per  step  so  can be very effective. Often  function evaluations are the  slowest part of  the computation and, as  well, no derivative is  needed. Because  it  can be  very efficient, the secant  method  is used in  the default method  of <code>find_zero</code> when  called with a single initial starting point.</p><p><a href="https://en.wikipedia.org/wiki/Steffensen%27s_method">Steffensen&#39;s</a> method is a quadratically converging. derivative-free method  which uses a secant  line  based on <span>$x_n$</span> and <span>$x_n + f(x_n)$</span>.  Though of  higher  order, it requires  additional function calls per step and depends on a  good initial starting value. Other  derivative free methods are available, trading off  increased function calls for higher-order convergence. They may be  of interest when arbitrary  precision is needed. A  measure of efficiency is <span>$q^{1/r}$</span> where <span>$q$</span> is the order of convergence and <span>$r$</span> the number of function calls per step.   With this measure, the secant method  would be <span>$\approx (1.618)^{1/1}$</span> and Steffensen&#39;s  would be less (<span>$2^{1/2}$</span>).</p><hr/><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Secant" href="#Roots.Secant"><code>Roots.Secant</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Secant()
Order1()
Orderφ()</code></pre><p>The <code>Order1()</code> method is an alias for <code>Secant</code>. It specifies the <a href="https://en.wikipedia.org/wiki/Secant_method">secant method</a>. This method keeps two values in its state, <code>xₙ</code> and <code>xₙ₋₁</code>. The updated point is the intersection point of <span>$x$</span> axis with the secant line formed from the two points. The secant method uses <span>$1$</span> function evaluation per step and has order <code>φ≈ (1+sqrt(5))/2</code>.</p><p>The error, <code>eᵢ = xᵢ - α</code>, satisfies <code>eᵢ₊₂ = f[xᵢ₊₁,xᵢ,α] / f[xᵢ₊₁,xᵢ] * (xᵢ₊₁-α) * (xᵢ - α)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/secant.jl#L1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Order1" href="#Roots.Order1"><code>Roots.Order1</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Secant()
Order1()
Orderφ()</code></pre><p>The <code>Order1()</code> method is an alias for <code>Secant</code>. It specifies the <a href="https://en.wikipedia.org/wiki/Secant_method">secant method</a>. This method keeps two values in its state, <code>xₙ</code> and <code>xₙ₋₁</code>. The updated point is the intersection point of <span>$x$</span> axis with the secant line formed from the two points. The secant method uses <span>$1$</span> function evaluation per step and has order <code>φ≈ (1+sqrt(5))/2</code>.</p><p>The error, <code>eᵢ = xᵢ - α</code>, satisfies <code>eᵢ₊₂ = f[xᵢ₊₁,xᵢ,α] / f[xᵢ₊₁,xᵢ] * (xᵢ₊₁-α) * (xᵢ - α)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/secant.jl#L1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Steffensen" href="#Roots.Steffensen"><code>Roots.Steffensen</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Steffensen()</code></pre><p>The quadratically converging <a href="https://en.wikipedia.org/wiki/Steffensen&#39;s_method#Simple_description">Steffensen</a> method is used for the derivative-free <code>Order2()</code> algorithm. Unlike the quadratically converging Newton&#39;s method, no derivative is necessary, though like Newton&#39;s method, two function calls per step are. Steffensen&#39;s algorithm is more sensitive than Newton&#39;s method to poor initial guesses when <code>f(x)</code> is large, due to how <code>f&#39;(x)</code> is approximated. The <code>Order2</code> method replaces a Steffensen step with a secant step when <code>f(x)</code> is large.</p><p>The error, <code>eᵢ - α</code>, satisfies <code>eᵢ₊₁ = f[xᵢ, xᵢ+fᵢ, α] / f[xᵢ,xᵢ+fᵢ] ⋅ (1 - f[xᵢ,α] ⋅ eᵢ²</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/steffensen.jl#L1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Order2" href="#Roots.Order2"><code>Roots.Order2</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Order2</code></pre><p><a href="#Roots.Steffensen"><code>Steffensen</code></a> with a guard on the secant step.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/steffensen.jl#L20-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Order5" href="#Roots.Order5"><code>Roots.Order5</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Order5()
KumarSinghAkanksha()</code></pre><p>Implements an order 5 algorithm from <em>A New Fifth Order Derivative Free Newton-Type Method for Solving Nonlinear Equations</em> by Manoj Kumar, Akhilesh Kumar Singh, and Akanksha, Appl. Math. Inf. Sci. 9, No. 3, 1507-1513 (2015), DOI: <a href="https://doi.org/10.12785/amis/090346">10.12785/amis/090346</a>. Four function calls per step are needed.  The <code>Order5</code> method replaces a Steffensen step with a secant step when <code>f(x)</code> is large.</p><p>The error, <code>eᵢ = xᵢ - α</code>, satisfies <code>eᵢ₊₁ = K₁ ⋅ K₅ ⋅ M ⋅ eᵢ⁵ + O(eᵢ⁶)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/order5.jl#L1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Order8" href="#Roots.Order8"><code>Roots.Order8</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Order8()
Thukral8()</code></pre><p>Implements an eighth-order algorithm from <em>New Eighth-Order Derivative-Free Methods for Solving Nonlinear Equations</em> by Rajinder Thukral, International Journal of Mathematics and Mathematical Sciences Volume 2012 (2012), Article ID 493456, 12 pages DOI: <a href="https://doi.org/10.1155/2012/493456">10.1155/2012/493456</a>. Four function calls per step are required.  The <code>Order8</code> method replaces a Steffensen step with a secant step when <code>f(x)</code> is large.</p><p>The error, <code>eᵢ = xᵢ - α</code>, is expressed as <code>eᵢ₊₁ = K ⋅ eᵢ⁸</code> in (2.25) of the paper for an explicit <code>K</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/order8.jl#L1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Order16" href="#Roots.Order16"><code>Roots.Order16</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Order16()
Thukral16()</code></pre><p>Implements the order 16 algorithm from <em>New Sixteenth-Order Derivative-Free Methods for Solving Nonlinear Equations</em> by R. Thukral, American Journal of Computational and Applied Mathematics p-ISSN: 2165-8935;    e-ISSN: 2165-8943; 2012;  2(3): 112-118 DOI: <a href="https://doi.org/10.5923/j.ajcam.20120203.08">10.5923/j.ajcam.20120203.08</a>.</p><p>Five function calls per step are required. Though rapidly converging, this method generally isn&#39;t faster (fewer function calls/steps) over other methods when using <code>Float64</code> values, but may be useful for solving over <code>BigFloat</code>.  The <code>Order16</code> method replaces a Steffensen step with a secant step when <code>f(x)</code> is large.</p><p>The error, <code>eᵢ = xᵢ - α</code>, is expressed as <code>eᵢ₊₁ = K⋅eᵢ¹⁶</code> for an explicit <code>K</code> in equation (50) of the paper.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/order16.jl#L1-L21">source</a></section></article><h2 id="Bracketing-methods"><a class="docs-heading-anchor" href="#Bracketing-methods">Bracketing methods</a><a id="Bracketing-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Bracketing-methods" title="Permalink"></a></h2><p>The <a href="https://en.wikipedia.org/wiki/Bisection_method">bisection</a> method identifies a zero of a <em>continuous</em> function between <span>$a$</span> and <span>$b$</span>  when  <span>$f(a)$</span> and  <span>$f(b)$</span> have different  signs. (The interval <span>$[a,b]$</span> is called a bracketing interval when <span>$f(a)\cdot  f(b)  &lt;0$</span>.)  The basic  algorithm is particularly simple, an interval  <span>$[a_i,b_i]$</span> is  split  at  <span>$c =  (a_i+b_i)/2$</span>. Either  <span>$f(c)=0$</span>,  or one  of  <span>$[a_i,c]$</span>  or  <span>$[c,b_i]$</span> is a bracketing  interval,  which is  called  <span>$[a_{i+1},b_{i+1}]$</span>. From this  description,  we  see  that  <span>$[a_i,b_i]$</span> has length  <span>$2^{-i}$</span> times the length of <span>$[a_0,b_0]$</span>, so  the intervals will eventually terminate by finding  a zero, <span>$c$</span>,  or converge  to a zero. This convergence is slow (the efficiency  is only <span>$1$</span>, but guaranteed. For  <code>16</code>-, <code>32</code>-, and <code>64</code>-bit  floating point  values, a  reinterpretation  of  how the midpoint  (<span>$c$</span>) is found  leads  to convergence  in  no more  than   <span>$64$</span> iterations, unlike the midpoint found above, where some cases can take many more steps to converge.</p><p>In floating point,  by  guaranteed  convergence we have either an exact zero or a bracketing interval  consisting   of  two  adjacent floating point values. When applied to <em>non</em>-continuous  functions,  this algorithm  will identify   an exact  zero or  a zero crossing   of the function. (E.g., applied  to  <span>$f(x)=1/x$</span> it  will  find  <span>$0$</span>.)</p><p>The default selection of  midpoint described above includes no information  about the function <span>$f$</span> beyond its  sign. Algorithms exploiting  the shape of the function  can be significantly more efficient. For example, the bracketing method <code>Roots.AlefeldPotraShi</code> due to <a href="https://dl.acm.org/doi/10.1145/210089.210111">Alefeld, Potra, and Shi</a> has  efficiency <span>$\approx 1.6686$</span>. This method  is  also   used in the  default method for <code>find_zero</code> when a  single initial starting point is given if a bracketing interval is identified.</p><hr/><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Bisection" href="#Roots.Bisection"><code>Roots.Bisection</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Bisection()</code></pre><p>If possible, will use the bisection method over <code>Float64</code> values. The bisection method starts with a bracketing interval <code>[a,b]</code> and splits it into two intervals <code>[a,c]</code> and <code>[c,b]</code>, If <code>c</code> is not a zero, then one of these two will be a bracketing interval and the process continues. The computation of <code>c</code> is done by <code>_middle</code>, which reinterprets floating point values as unsigned integers and splits there. It was contributed  by  <a href="https://gist.github.com/jwmerrill/9012954">Jason Merrill</a>. This method avoids floating point issues and when the tolerances are set to zero (the default) guarantees a &quot;best&quot; solution (one where a zero is found or the bracketing interval is of the type <code>[a, nextfloat(a)]</code>).</p><p>When tolerances are given, this algorithm terminates when the interval length is less than or equal to the tolerance <code>max(δₐ, 2abs(u)δᵣ)</code> with <code>u</code> in <code>{a,b}</code> chosen by the smaller of <code>|f(a)|</code> and <code>|f(b)|</code>, or  or the function value is less than <code>max(tol, min(abs(a), abs(b)) * rtol)</code>. The latter is used only if the default tolerances (<code>atol</code> or <code>rtol</code>) are adjusted.</p><p>When solving <span>$f(x,p) = 0$</span> for <span>$x^*(p)$</span> using <code>Bisection</code> one can not take the derivative directly via automatatic differentiation, as the algorithm is not differentiable. See <a href="https://juliamath.github.io/Roots.jl/stable/roots/#Sensitivity">Sensitivity</a> in the documentation for alternatives.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Bracketing/bisection.jl#L1-L27">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.A42" href="#Roots.A42"><code>Roots.A42</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.A42()</code></pre><p>Bracketing method which finds the root of a continuous function within a provided bracketing interval <code>[a, b]</code>, without requiring derivatives. It is based on Algorithm 4.2 described in: G. E. Alefeld, F. A. Potra, and Y. Shi, &quot;Algorithm 748: enclosing zeros of continuous functions,&quot; ACM Trans. Math. Softw. 21, 327–344 (1995), DOI: <a href="https://doi.org/10.1145/210089.210111">10.1145/210089.210111</a>. The asymptotic efficiency index, <span>$q^{1/k}$</span>, is <span>$(2 + 7^{1/2})^{1/3} = 1.6686...$</span>.</p><p>Originally by John Travers.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The paper refenced above shows that for a continuously differentiable <span>$f$</span> over <span>$[a,b]$</span> with a simple root  the algorithm terminates at a zero or asymptotically the steps are of the inverse cubic type (Lemma 5.1). This is proved under an assumption that <span>$f$</span> is four-times continuously differentiable.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Bracketing/alefeld_potra_shi.jl#L293-L309">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.AlefeldPotraShi" href="#Roots.AlefeldPotraShi"><code>Roots.AlefeldPotraShi</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.AlefeldPotraShi()</code></pre><p>Follows Algorithm 4.1 in &quot;ON ENCLOSING SIMPLE ROOTS OF NONLINEAR EQUATIONS&quot;, by Alefeld, Potra, Shi; DOI: <a href="https://doi.org/10.1090/S0025-5718-1993-1192965-2">10.1090/S0025-5718-1993-1192965-2</a>.</p><p>The order of convergence is <code>2 + √5</code>; asymptotically there are 3 function evaluations per step. Asymptotic efficiency index is <span>$(2+√5)^{1/3} ≈ 1.618...$</span>. Less efficient, but can run faster than the related <a href="#Roots.A42"><code>A42</code></a> method.</p><p>Originally by John Travers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Bracketing/alefeld_potra_shi.jl#L234-L245">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Brent" href="#Roots.Brent"><code>Roots.Brent</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.Brent()</code></pre><p>An implementation of <a href="https://en.wikipedia.org/wiki/Brent%27s_method">Brent&#39;s</a> (or Brent-Dekker) method. This method uses a choice of inverse quadratic interpolation or a secant step, falling back on bisection if necessary.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Bracketing/brent.jl#L1-L9">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Chandrapatla" href="#Roots.Chandrapatla"><code>Roots.Chandrapatla</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.Chandrapatla()</code></pre><p>Use <a href="https://doi.org/10.1016/S0965-9978(96)00051-8">Chandrapatla&#39;s algorithm</a> (cf. <a href="https://www.google.com/books/edition/Computational_Physics/cC-8BAAAQBAJ?hl=en&amp;gbpv=1&amp;pg=PA95&amp;printsec=frontcover">Scherer</a>) to solve <span>$f(x) = 0$</span>.</p><p>Chandrapatla&#39;s algorithm chooses between an inverse quadratic step or a bisection step based on a computed inequality.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Bracketing/chandrapatlu.jl#L1-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Ridders" href="#Roots.Ridders"><code>Roots.Ridders</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.Ridders()</code></pre><p>Implements <a href="https://en.wikipedia.org/wiki/Ridders%27_method">Ridders&#39;</a> method. This bracketing method finds the midpoint, <code>x₁</code>; then interpolates an exponential; then uses false position with the interpolated value to find <code>c</code>. If <code>c</code> and <code>x₁</code> form a bracket is used, otherwise the subinterval <code>[a,c]</code> or <code>[c,b]</code> is used.</p><p>Example:</p><pre><code class="language-julia-repl hljs">julia&gt; using Roots

julia&gt; find_zero(x -&gt; exp(x) - x^4, (5, 15), Roots.Ridders()) ≈ 8.61316945644
true

julia&gt; find_zero(x -&gt; x*exp(x) - 10, (-100, 100), Roots.Ridders()) ≈ 1.74552800274
true

julia&gt; find_zero(x -&gt; tan(x)^tan(x) - 1e3, (0, 1.5), Roots.Ridders()) ≈ 1.3547104419
true</code></pre><p><a href="https://cs.fit.edu/~dmitra/SciComp/Resources/RidderMethod.pdf">Ridders</a> showed the error satisfies <code>eₙ₊₁ ≈ 1/2 eₙeₙ₋₁eₙ₋₂ ⋅ (g^2-2fh)/f</code> for <code>f=F&#39;, g=F&#39;&#39;/2, h=F&#39;&#39;&#39;/6</code>, suggesting converence at rate <code>≈ 1.839...</code>. It uses two function evaluations per step, so  its order of convergence is <code>≈ 1.225...</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Bracketing/ridders.jl#L1-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.ITP" href="#Roots.ITP"><code>Roots.ITP</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.ITP(;[κ₁-0.2, κ₂=2, n₀=1])</code></pre><p>Use the <a href="https://en.wikipedia.org/wiki/ITP_method">ITP</a> bracketing method.  This method claims it &quot;is the first root-finding algorithm that achieves the superlinear convergence of the secant method while retaining the optimal worst-case performance of the bisection method.&quot;</p><p>The values <code>κ1</code>, <code>κ₂</code>, and <code>n₀</code> are tuning parameters.</p><p>The <a href="https://docs.rs/kurbo/0.8.1/kurbo/common/fn.solve_itp.html">suggested</a> value of <code>κ₁</code> is <code>0.2/(b-a)</code>, but the default here is <code>0.2</code>. The value of <code>κ₂</code> is <code>2</code>, and the default value of <code>n₀</code> is <code>1</code>.</p><p><strong>Note:</strong></p><p>Suggested on <a href="https://discourse.julialang.org/t/julia-implementation-of-the-interpolate-truncate-project-itp-root-finding-algorithm/77739">discourse</a> by <code>@TheLateKronos</code>, who supplied the original version of the code.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Bracketing/itp.jl#L1-L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.FalsePosition" href="#Roots.FalsePosition"><code>Roots.FalsePosition</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">FalsePosition([galadino_factor])</code></pre><p>Use the <a href="https://en.wikipedia.org/wiki/False_position_method">false position</a> method to find a zero for the function <code>f</code> within the bracketing interval <code>[a,b]</code>.</p><p>The false position method is a modified bisection method, where the midpoint between <code>[aₖ, bₖ]</code> is chosen to be the intersection point of the secant line with the <span>$x$</span> axis, and not the average between the two values.</p><p>To speed up convergence for concave functions, this algorithm implements the <span>$12$</span> reduction factors of Galdino (<em>A family of regula falsi root-finding methods</em>). These are specified by number, as in <code>FalsePosition(2)</code> or by one of three names <code>FalsePosition(:pegasus)</code>, <code>FalsePosition(:illinois)</code>, or <code>FalsePosition(:anderson_bjork)</code> (the default). The default choice has generally better performance than the others, though there are exceptions.</p><p>For some problems, the number of function calls can be greater than for the <code>Bisection</code> method, but generally this algorithm will make fewer function calls.</p><p>Examples</p><pre><code class="nohighlight hljs">find_zero(x -&gt; x^5 - x - 1, (-2, 2), FalsePosition())</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Bracketing/false_position.jl#L3-L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.LithBoonkkampIJzermanBracket" href="#Roots.LithBoonkkampIJzermanBracket"><code>Roots.LithBoonkkampIJzermanBracket</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LithBoonkkampIJzermanBracket()</code></pre><p>A bracketing method which is a modification of Brent&#39;s method due to <a href="https://doi.org/10.1016/j.amc.2017.09.003">Lith, Boonkkamp, and IJzerman</a>. The best possible convergence rate is 2.91.</p><p>A function, its derivative, and a bracketing interval need to be specified.</p><p>The state includes the 3 points – a bracket <code>[a,b]</code> (<code>b=xₙ</code> has <code>f(b)</code> closest to <code>0</code>) and <code>c=xₙ₋₁</code> – and the corresponding values for the function and its derivative at these three points.</p><p>The next proposed step is either a <code>S=2</code> or <code>S=3</code> selection for the <a href="#Roots.LithBoonkkampIJzerman"><code>LithBoonkkampIJzerman</code></a> methods with derivative information included only if it would be of help. The proposed is modified if it is dithering. The proposed is compared against a bisection step; the one in the bracket and with the smaller function value is chosen as the next step.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/lith.jl#L414-L436">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.BracketedHalley" href="#Roots.BracketedHalley"><code>Roots.BracketedHalley</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BracketedHalley</code></pre><p>For a bracket <code>[a,b]</code>, uses the <a href="#Roots.Halley"><code>Roots.Halley</code></a> method starting at the <code>x</code> value for which <code>fa</code> or <code>fb</code> is closest to <code>0</code>. Uses the <code>Roots.AbstractAlefeldPotraShi</code> framework to enforce the bracketing, taking an additional double secant step each time.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/halley_like.jl#L203-L207">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.BracketedChebyshev" href="#Roots.BracketedChebyshev"><code>Roots.BracketedChebyshev</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BracketedChebyshev</code></pre><p>For a bracket <code>[a,b]</code>, uses the <a href="#Roots.QuadraticInverse"><code>Roots.QuadraticInverse</code></a> method starting at the <code>x</code> value for which <code>fa</code> or <code>fb</code> is closest to <code>0</code>. Uses the <code>Roots.AbstractAlefeldPotraShi</code> framework to enforce the bracketing, taking an additional double secant step each time.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/halley_like.jl#L220-L224">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.BracketedSchroder" href="#Roots.BracketedSchroder"><code>Roots.BracketedSchroder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BracketedSchroder</code></pre><p>For a bracket <code>[a,b]</code>, uses the <a href="#Roots.Schroder"><code>Roots.Schroder</code></a> method starting at the <code>x</code> value for which <code>fa</code> or <code>fb</code> is closest to <code>0</code>. Uses the <code>Roots.AbstractAlefeldPotraShi</code> framework to enforce the bracketing, taking an additional double secant step each time.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/halley_like.jl#L236-L240">source</a></section></article><h2 id="Non-simple-zeros"><a class="docs-heading-anchor" href="#Non-simple-zeros">Non-simple zeros</a><a id="Non-simple-zeros-1"></a><a class="docs-heading-anchor-permalink" href="#Non-simple-zeros" title="Permalink"></a></h2><p>The order of convergence for most methods is for <em>simple</em> zeros, values <span>$\alpha$</span> where <span>$f(x) = (x-\alpha) \cdot g(x)$</span>, with <span>$g(\alpha)$</span> being non-zero. For methods which are of order <span>$k$</span> for non-simple zeros, usually an additional function call is needed per step. For example, this is the case for <code>Roots.Newton</code> as compared to <code>Roots.Schroder</code>.</p><p>Derivative-free methods for non-simple zeros have the following implemented:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.King" href="#Roots.King"><code>Roots.King</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.King()</code></pre><p>A superlinear (order <code>1.6...</code>) modification of the secant method for multiple roots. Presented in A SECANT METHOD FOR MULTIPLE ROOTS, by RICHARD F. KING, BIT 17 (1977), 321-328</p><p>The basic idea is similar to Schroder&#39;s method: apply the secant method to  <code>f/f&#39;</code>. However, this uses <code>f&#39; ~ fp = (fx - f(x-fx))/fx</code> (a Steffensen step). In this implementation, <code>Order1B</code>, when <code>fx</code> is too big, a single secant step of <code>f</code> is used.</p><p>The <em>asymptotic</em> error, <code>eᵢ = xᵢ - α</code>, is given by <code>eᵢ₊₂ = 1/2⋅G&#39;&#39;/G&#39;⋅ eᵢ⋅eᵢ₊₁ + (1/6⋅G&#39;&#39;&#39;/G&#39; - (1/2⋅G&#39;&#39;/G&#39;))^2⋅eᵢ⋅eᵢ₊₁⋅(eᵢ+eᵢ₊₁)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/king.jl#L1-L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Order1B" href="#Roots.Order1B"><code>Roots.Order1B</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.Order1B()</code></pre><p><a href="#Roots.King"><code>King</code></a> method with guarded secant step.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/king.jl#L18-L22">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Esser" href="#Roots.Esser"><code>Roots.Esser</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.Esser()</code></pre><p>Esser&#39;s method. This is a quadratically convergent method that, like Schroder&#39;s method, does not depend on the multiplicity of the zero. Schroder&#39;s method has update step <code>x - r2/(r2-r1) * r1</code>, where <code>ri = fⁱ⁻¹/fⁱ</code>. Esser approximates <code>f&#39; ~ f[x-h, x+h], f&#39;&#39; ~ f[x-h,x,x+h]</code>, where <code>h = fx</code>, as with Steffensen&#39;s method, Requiring 3 function calls per step. The implementation <code>Order2B</code> uses a secant step when <code>|fx|</code> is considered too large.</p><p>Esser, H. Computing (1975) 14: 367. DOI: <a href="https://doi.org/10.1007/BF02253547">10.1007/BF02253547</a> Eine stets quadratisch konvergente Modification des Steffensen-Verfahrens</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">f(x) = cos(x) - x
g(x) = f(x)^2
x0 = pi/4
find_zero(f, x0, Order2(), verbose=true)        #  3 steps / 7 function calls
find_zero(f, x0, Roots.Order2B(), verbose=true) #  4 / 9
find_zero(g, x0, Order2(), verbose=true)        #  22 / 45
find_zero(g, x0, Roots.Order2B(), verbose=true) #  4 / 10</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/esser.jl#L2-L29">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Order2B" href="#Roots.Order2B"><code>Roots.Order2B</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.Order2B()</code></pre><p><a href="#Roots.Esser"><code>Esser</code></a> method with guarded secant step.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/esser.jl#L32-L36">source</a></section></article><p>For non-simple zeros, Schroder showed an additional derivative can  be used to yield quadratic convergence based on Newton&#39;s method:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Schroder" href="#Roots.Schroder"><code>Roots.Schroder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.Schroder()</code></pre><p>Schröder&#39;s method, like Halley&#39;s method, utilizes <code>f</code>, <code>f&#39;</code>, and <code>f&#39;&#39;</code>. Unlike Halley it is quadratically converging, but this is independent of the multiplicity of the zero (cf. Schröder, E. &quot;Über unendlich viele Algorithmen zur Auflösung der Gleichungen.&quot; Math. Ann. 2, 317-365, 1870; <a href="http://mathworld.wolfram.com/SchroedersMethod.html">mathworld</a>).</p><p>Schröder&#39;s method applies Newton&#39;s method to <code>f/f&#39;</code>, a function with all simple zeros.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">m = 2
f(x) = (cos(x)-x)^m
fp(x) = (-x + cos(x))*(-2*sin(x) - 2)
fpp(x) = 2*((x - cos(x))*cos(x) + (sin(x) + 1)^2)
find_zero((f, fp, fpp), pi/4, Roots.Halley())     # 14 steps
find_zero((f, fp, fpp), 1.0, Roots.Schroder())    # 3 steps</code></pre><p>(Whereas, when <code>m=1</code>, Halley is 2 steps to Schröder&#39;s 3.)</p><p>If function evaluations are expensive one can pass in a function which returns <code>(f, f/f&#39;,f&#39;/f&#39;&#39;)</code> as follows</p><pre><code class="nohighlight hljs">find_zero(x -&gt; (sin(x), sin(x)/cos(x), -cos(x)/sin(x)), 3.0, Roots.Schroder())</code></pre><p>This can be advantageous if the derivatives are easily computed from the value of <code>f</code>, but otherwise would be expensive to compute.</p><p>The error, <code>eᵢ = xᵢ - α</code>, is the same as <code>Newton</code> with <code>f</code> replaced by <code>f/f&#39;</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/halley_like.jl#L146-L186">source</a></section></article><p>A family of methods for non-simple zeros which require <span>$k$</span> derivatives to be order <span>$k$</span>, with <span>$k=2$</span> yielding Schroder&#39;s method, are implemented in:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.AbstractThukralBMethod" href="#Roots.AbstractThukralBMethod"><code>Roots.AbstractThukralBMethod</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AbstractThukralBMethod</code></pre><p>Abstract type for <code>ThukralXB</code> methods for <code>X</code> being <code>2</code>,<code>3</code>,<code>4</code>, or <code>5</code>.</p><p>These are a family of methods which are</p><ul><li>efficient (order <code>X</code>) for non-simple roots (e.g. <code>Thukral2B</code> is the <code>Schroder</code> method)</li><li>take <code>X+1</code> function calls per step</li><li>require <code>X</code> derivatives. These can be passed as a tuple of functions, <code>(f, f&#39;, f&#39;&#39;, …)</code>, <em>or</em> as</li></ul><p>a function returning the ratios: <code>x -&gt; (f(x), f(x)/f&#39;(x), f&#39;(x)/f&#39;&#39;(x), …)</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using ForwardDiff
Base.adjoint(f::Function)  = x  -&gt; ForwardDiff.derivative(f, float(x))
f(x) = (exp(x) + x - 2)^6
x0 = 1/4
find_zero((f, f&#39;, f&#39;&#39;), x0, Roots.Halley())               # 14 iterations; ≈ 48 function evaluations
find_zero((f, f&#39;, f&#39;&#39;), big(x0), Roots.Thukral2B())       #  3 iterations; ≈ 9 function evaluations
find_zero((f, f&#39;, f&#39;&#39;, f&#39;&#39;&#39;), big(x0), Roots.Thukral3B()) #  2 iterations; ≈ 8 function evaluations</code></pre><p><strong>Reference</strong></p><p><em>Introduction to a family of Thukral <span>$k$</span>-order method for finding multiple zeros of nonlinear equations</em>, R. Thukral, JOURNAL OF ADVANCES IN MATHEMATICS 13(3):7230-7237, DOI: <a href="https://doi.org/10.24297/jam.v13i3.6146">10.24297/jam.v13i3.6146</a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Derivative/thukralb.jl#L2-L30">source</a></section></article><h2 id="Hybrid-methods"><a class="docs-heading-anchor" href="#Hybrid-methods">Hybrid  methods</a><a id="Hybrid-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Hybrid-methods" title="Permalink"></a></h2><p>A useful  strategy  is   to  begin with a non-bracketing  method and switch to a bracketing method should a bracket be encountered. This  allows   for the identification of zeros which are not surrounded by a bracket, and have guaranteed convergence  should a bracket be  encountered.  It  is  used  by default by <code>find_zero(f,a)</code>.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Order0" href="#Roots.Order0"><code>Roots.Order0</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Order0()</code></pre><p>The <code>Order0</code> method is engineered to be a more robust, though possibly slower, alternative to the other derivative-free root-finding methods. The implementation roughly follows the algorithm described in <em>Personal Calculator Has Key to Solve Any Equation <span>$f(x) = 0$</span></em>, the SOLVE button from the <a href="http://www.hpl.hp.com/hpjournal/pdfs/IssuePDFs/1979-12.pdf">HP-34C</a>. The basic idea is to use a secant step. If along the way a bracket is found, switch to a bracketing algorithm, using <code>AlefeldPotraShi</code>.  If the secant step fails to decrease the function value, a quadratic step is used up to <span>$4$</span> times.</p><p>This is not really <span>$0$</span>-order: the secant method has order <span>$1.6...$</span> <a href="https://en.wikipedia.org/wiki/Secant_method#Comparison_with_other_root-finding_methods">Wikipedia</a> and the the bracketing method has order <span>$1.6180...$</span> <a href="http://www.ams.org/journals/mcom/1993-61-204/S0025-5718-1993-1192965-2/S0025-5718-1993-1192965-2.pdf">Wikipedia</a> so for reasonable starting points and functions, this algorithm should be superlinear, and relatively robust to non-reasonable starting points.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/DerivativeFree/order0.jl#L1-L23">source</a></section></article><h2 id="All-zeros"><a class="docs-heading-anchor" href="#All-zeros">All zeros</a><a id="All-zeros-1"></a><a class="docs-heading-anchor-permalink" href="#All-zeros" title="Permalink"></a></h2><p>The <code>find_zeros</code> function heuristically scans an interval for all zeros using a combination of bracketing and non-bracketing methods. The <code>AllZeros</code> method may be passed to <code>solve</code> to call this.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.AllZeros" href="#Roots.AllZeros"><code>Roots.AllZeros</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AllZeros</code></pre><p>Type to indicate to <code>solve</code> that <code>find_zeros</code> should be used to solve the given  <code>ZeroProblem</code>.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">julia&gt; Z = ZeroProblem(cos, (0, 2pi));

julia&gt; solve(Z, AllZeros())
2-element Vector{Float64}:
 1.5707963267948966
 4.71238898038469</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/find_zeros.jl#L397-L413">source</a></section></article><h2 id="Rates-of-convergence"><a class="docs-heading-anchor" href="#Rates-of-convergence">Rates of convergence</a><a id="Rates-of-convergence-1"></a><a class="docs-heading-anchor-permalink" href="#Rates-of-convergence" title="Permalink"></a></h2><p>The order of a method is <span>$q$</span>, where <span>$e_{i+1} \approx e_i^q$</span>. Newton&#39;s method is famously quadratic <strong>for</strong> simple roots; the secant method of order <span>$q \approx \varphi=1.618\dots$</span>. However, <span>$p=2$</span> calls are needed for Newton&#39;s method, and only <span>$p=1$</span> for the secant method. The asymptotic efficiency is <span>$q^{1/p}$</span>, which penalizes function calls. There are other order <span>$k$</span> methods taking <span>$k$</span> function calls per step, e.g., Halley&#39;s; others take fewer, as seen below. Many use inverse quadratic steps, others inverse cubic–these have order <span>$q$</span> solving <span>$q^{s+1}-2q^s+1$</span> (<span>$s=3$</span> for quadratic). For robust methods, generally <span>$1$</span> additional function call is needed to achieve the convergence rate, <code>Schroder</code> being a good example.</p><table><tr><th style="text-align: left">Type</th><th style="text-align: left">Method</th><th style="text-align: left">Order</th><th style="text-align: left">F evals</th><th style="text-align: left">Asymptotic efficiency</th></tr><tr><td style="text-align: left">Hybrid</td><td style="text-align: left">Order0</td><td style="text-align: left"></td><td style="text-align: left"></td><td style="text-align: left"><span>$\approx 1.618\dots$</span></td></tr><tr><td style="text-align: left">Derivative Free</td><td style="text-align: left">Secant</td><td style="text-align: left"><span>$\varphi=1.618\dots$</span></td><td style="text-align: left"><span>$1$</span></td><td style="text-align: left"><span>$1.618\dots$</span></td></tr><tr><td style="text-align: left">Derivative Free</td><td style="text-align: left">Steffensen</td><td style="text-align: left"><span>$2$</span></td><td style="text-align: left"><span>$2$</span></td><td style="text-align: left"><span>$1.414\dots$</span></td></tr><tr><td style="text-align: left">Derivative Free</td><td style="text-align: left">Order5</td><td style="text-align: left"><span>$5$</span></td><td style="text-align: left"><span>$4$</span></td><td style="text-align: left"><span>$1.495\dots$</span></td></tr><tr><td style="text-align: left">Derivative Free</td><td style="text-align: left">Order8</td><td style="text-align: left"><span>$8$</span></td><td style="text-align: left"><span>$4$</span></td><td style="text-align: left"><span>$1.681\dots$</span></td></tr><tr><td style="text-align: left">Derivative Free</td><td style="text-align: left">Order16</td><td style="text-align: left"><span>$16$</span></td><td style="text-align: left"><span>$5$</span></td><td style="text-align: left"><span>$1.718\dots$</span></td></tr><tr><td style="text-align: left">Classical</td><td style="text-align: left">Newton</td><td style="text-align: left"><span>$2$</span></td><td style="text-align: left"><span>$2$</span></td><td style="text-align: left"><span>$1.414\dots$</span></td></tr><tr><td style="text-align: left">Classical</td><td style="text-align: left">Halley</td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$1.442\dots$</span></td></tr><tr><td style="text-align: left">Classical</td><td style="text-align: left">QuadraticInverse</td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$1.442\dots$</span></td></tr><tr><td style="text-align: left">Classical</td><td style="text-align: left">ChebyshevLike</td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$1.442\dots$</span></td></tr><tr><td style="text-align: left">Classical</td><td style="text-align: left">SuperHalley</td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$1.442\dots$</span></td></tr><tr><td style="text-align: left">MultiStep</td><td style="text-align: left">LithBoonkkampIJzerman{S,D}</td><td style="text-align: left"><span>$p^s=\sum p^k(d+\sigma_k)$</span></td><td style="text-align: left"><span>$D+1$</span></td><td style="text-align: left">varies, <span>$1.92\dots$</span> max</td></tr><tr><td style="text-align: left">Bracketing</td><td style="text-align: left">BisectionExact</td><td style="text-align: left"><span>$1$</span></td><td style="text-align: left"><span>$1$</span></td><td style="text-align: left"><span>$1$</span></td></tr><tr><td style="text-align: left">Bracketing</td><td style="text-align: left">A42</td><td style="text-align: left"><span>$(2 + 7^{1/2})$</span></td><td style="text-align: left"><span>$3,4$</span></td><td style="text-align: left"><span>$(2 + 7^{1/2})^{1/3} = 1.6686\dots$</span></td></tr><tr><td style="text-align: left">Bracketing</td><td style="text-align: left">AlefeldPotraShi</td><td style="text-align: left"></td><td style="text-align: left"><span>$3,4$</span></td><td style="text-align: left"><span>$1.618\dots$</span></td></tr><tr><td style="text-align: left">Bracketing</td><td style="text-align: left">Brent</td><td style="text-align: left"><span>$\leq 1.89\dots$</span></td><td style="text-align: left"><span>$1$</span></td><td style="text-align: left"><span>$\leq 1.89\dots$</span></td></tr><tr><td style="text-align: left">Bracketing</td><td style="text-align: left">ITP</td><td style="text-align: left"><span>$\leq \varphi$</span></td><td style="text-align: left"><span>$1$</span></td><td style="text-align: left"><span>$\leq \varphi$</span></td></tr><tr><td style="text-align: left">Bracketing</td><td style="text-align: left">Ridders</td><td style="text-align: left"><span>$1.83\dots$</span></td><td style="text-align: left"><span>$2$</span></td><td style="text-align: left"><span>$1.225\dots$</span></td></tr><tr><td style="text-align: left">Bracketing</td><td style="text-align: left">FalsePosition</td><td style="text-align: left"><span>$1.442\dots$</span></td><td style="text-align: left"><span>$1$</span></td><td style="text-align: left"><span>$1.442\dots$</span></td></tr><tr><td style="text-align: left">Bracketing</td><td style="text-align: left">LithBoonkkampIJzermanBracket</td><td style="text-align: left"><span>$2.91$</span></td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$1.427\dots$</span></td></tr><tr><td style="text-align: left">Robust</td><td style="text-align: left">King</td><td style="text-align: left"><span>$\varphi=1.618\dots$</span></td><td style="text-align: left"><span>$2$</span></td><td style="text-align: left"><span>$1.272\dots$</span></td></tr><tr><td style="text-align: left">Robust</td><td style="text-align: left">Esser</td><td style="text-align: left"><span>$2$</span></td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$1.259\dots$</span></td></tr><tr><td style="text-align: left">Robust</td><td style="text-align: left">Schroder</td><td style="text-align: left"><span>$2$</span></td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$1.259\dots$</span></td></tr><tr><td style="text-align: left">Robust</td><td style="text-align: left">Thukral3</td><td style="text-align: left"><span>$3$</span></td><td style="text-align: left"><span>$4$</span></td><td style="text-align: left"><span>$1.316\dots$</span></td></tr><tr><td style="text-align: left">Robust</td><td style="text-align: left">Thukral4</td><td style="text-align: left"><span>$4$</span></td><td style="text-align: left"><span>$5$</span></td><td style="text-align: left"><span>$1.319\dots$</span></td></tr><tr><td style="text-align: left">Robust</td><td style="text-align: left">Thukral5</td><td style="text-align: left"><span>$5$</span></td><td style="text-align: left"><span>$6$</span></td><td style="text-align: left"><span>$1.307\dots$</span></td></tr></table><h2 id="Convergence"><a class="docs-heading-anchor" href="#Convergence">Convergence</a><a id="Convergence-1"></a><a class="docs-heading-anchor-permalink" href="#Convergence" title="Permalink"></a></h2><p>Identifying when an algorithm converges or diverges requires specifications of tolerances  and convergence criteria.</p><p>In the case of exact bisection, convergence is mathematically guaranteed. For floating point numbers, either an <em>exact</em> zero is found, or the bracketing interval can be subdivided into <span>$[a_n,b_n]$</span> with <span>$a_n$</span> and <span>$b_n$</span> being adjacent floating point values. That is <span>$b_n-a_n$</span> is as small as possible in floating point numbers. This can be considered a stopping criteria in <span>$\Delta x$</span>. For early termination (less precision but fewer function calls) a tolerance can be given so that if <span>$\Delta_n=b_n-a_n$</span> is small enough the algorithm stops successfully.  In floating point, assessing if <span>$b_n \approx a_n$</span> requires two tolerances: a <em>relative</em> tolerance, as the minimal differences in floating point values depend on the size of <span>$b_n$</span> and <span>$a_n$</span>, and an absolute tolerance for values near <span>$0$</span>. The values <code>xrtol</code> and <code>xatol</code> are passed to the <code>Base.isapprox</code> function to determine closeness.</p><p>Relying on the closeness of two <span>$x$</span> values will not be adequate for all problems, as there are examples where the difference <span>$\Delta_n=|x_n-x_{n-1}|$</span> can be quite small, <span>$0$</span> even, yet <span>$f(x_n)$</span> is not near a <span>$0$</span>. As such, for non-bracketing methods, a check on the size of <span>$f(x_n)$</span> is also used. As we find floating point approximations to <span>$\alpha$</span>, the zero, we must consider values small when <span>$f(\alpha(1+\epsilon))$</span> is small. By Taylor&#39;s approximation, we can expect this to be around <span>$\alpha\cdot \epsilon \cdot f&#39;(\alpha)$</span>. That is, small depends on the size of <span>$\alpha$</span> and the derivative at <span>$\alpha$</span>.  The former is handled by both relative and absolute tolerances (<code>rtol</code> and <code>atol</code>).  The size of <span>$f&#39;(\alpha)$</span> is problem dependent, and can be accommodated by larger relative or absolute tolerances.</p><p>When an algorithm returns  an  <code>NaN</code> value,  it terminates. This  can  happen near convergence or  may indicate some issues.  Early termination is checked for convergence  in the  size  of <span>$f(x_n)$</span> with a relaxed tolerance when <code>strict=false</code> is specified (the default).</p><div class="admonition is-info"><header class="admonition-header">Relative tolerances  and assessing  `f(x) ≈ 0`</header><div class="admonition-body"><p>The use of  relative tolerances  to  check  if   <span>$f(x)  \approx  0$</span> can lead  to spurious  answers  where  <span>$x$</span> is very large   (and  hence the relative  tolerance  is large). The return of  very  large solutions  should  be checked against expectations  of the  answer.</p></div></div><p>Deciding if an algorithm won&#39;t  terminate is  done  through  counting the number or  iterations performed; the default  adjusted through <code>maxiters</code>. As  most  algorithms are superlinear, convergence happens rapidly near  the answer, but  all the algorithms  can take  a while  to  get near  an  answer, even   when progress  is made. As  such, the maximum must be large enough to consider linear cases, yet small enough to avoid too many steps when an algorithm is non-convergent.</p><p>Convergence criteria are method dependent and are determined by  the  <code>Roots.assess_convergence</code>  methods.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.assess_convergence" href="#Roots.assess_convergence"><code>Roots.assess_convergence</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.assess_convergence(method, state, options)</code></pre><p>Assess if algorithm has converged.</p><p>Return a convergence flag and a Boolean indicating if algorithm has terminated (converged or not converged)</p><p>If algorithm hasn&#39;t converged this returns <code>(:not_converged, false)</code>.</p><p>If algorithm has stopped or converged, return flag and <code>true</code>. Flags are:</p><ul><li><p><code>:x_converged</code> if <code>xn1 ≈ xn</code>, typically with non-zero tolerances specified.</p></li><li><p><code>:f_converged</code> if  <code>|f(xn1)| &lt; max(atol, |xn1|*rtol)</code></p></li><li><p><code>:nan</code> or <code>:inf</code> if fxn1 is <code>NaN</code> or an infinity.</p></li><li><p><code>:not_converged</code> if algorithm should continue</p></li></ul><p>Does not check number of steps taken nor number of function evaluations.</p><p>In <code>decide_convergence</code>, stopped values (and <code>:x_converged</code> when <code>strict=false</code>) are checked for convergence with a relaxed tolerance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/convergence.jl#L244-L268">source</a></section></article><p>Default tolerances  are specified through the <code>Roots.default_tolerances</code> methods.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.default_tolerances" href="#Roots.default_tolerances"><code>Roots.default_tolerances</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">default_tolerances(M::AbstractUnivariateZeroMethod, [T], [S])</code></pre><p>The default tolerances for most methods are <code>xatol=eps(T)</code>, <code>xrtol=eps(T)</code>, <code>atol=4eps(S)</code>, and <code>rtol=4eps(S)</code>, with the proper units (absolute tolerances have the units of <code>x</code> and <code>f(x)</code>; relative tolerances are unitless). For <code>Complex{T}</code> values, <code>T</code> is used.</p><p>The number of iterations is limited by <code>maxiters=40</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/convergence.jl#L80-L90">source</a></section><section><div><pre><code class="language-julia hljs">default_tolerances(M::AbstractBisectionMethod, [T], [S])</code></pre><p>For <code>Bisection</code> when the <code>x</code> values are of type <code>Float64</code>, <code>Float32</code>, or <code>Float16</code>, the default tolerances are zero and there is no limit on the number of iterations. In this case, the algorithm is guaranteed to converge to an exact zero, or a point where the function changes sign at one of the answer&#39;s adjacent floating point values.</p><p>For other types, default non-zero tolerances for <code>xatol</code> and <code>xrtol</code> are given.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/Bracketing/bisection.jl#L65-L77">source</a></section></article><h2 id="Simplified-versions"><a class="docs-heading-anchor" href="#Simplified-versions">Simplified versions</a><a id="Simplified-versions-1"></a><a class="docs-heading-anchor-permalink" href="#Simplified-versions" title="Permalink"></a></h2><p>The abstractions and many checks for  convergence employed by <code>find_zero</code> have a performance cost. When that is a critical concern, there are  several &quot;simple&quot; methods provided which can offer improved performance.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.secant_method" href="#Roots.secant_method"><code>Roots.secant_method</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">secant_method(f, xs; [atol=0.0, rtol=8eps(), maxevals=1000])</code></pre><p>Perform secant method to solve <code>f(x) = 0.</code></p><p>The secant method is an iterative method with update step given by <code>b - fb/m</code> where <code>m</code> is the slope of the secant line between <code>(a,fa)</code> and <code>(b,fb)</code>.</p><p>The initial values can be specified as a pair of 2, as in <code>(x₀, x₁)</code> or <code>[x₀, x₁]</code>, or as a single value, <code>x₁</code> in which case a value of <code>x₀</code> is chosen.</p><p>The algorithm returns m when <code>abs(fm) &lt;= max(atol, abs(m) * rtol)</code>. If this doesn&#39;t occur before <code>maxevals</code> steps or the algorithm encounters an issue, a value of <code>NaN</code> is returned. If too many steps are taken, the current value is checked to see if there is a sign change for neighboring floating point values.</p><p>The <code>Order1</code> method for <code>find_zero</code> also implements the secant method. This one should be slightly faster, as there are fewer setup costs.</p><p>Examples:</p><pre><code class="language-julia hljs">Roots.secant_method(sin, (3,4))
Roots.secant_method(x -&gt; x^5 -x - 1, 1.1)</code></pre><div class="admonition is-info"><header class="admonition-header">Specialization</header><div class="admonition-body"><p>This function will specialize on the function <code>f</code>, so that the initial call can take more time than a call to the <code>Order1()</code> method, though subsequent calls will be much faster.  Using <code>FunctionWrappers.jl</code> can ensure that the initial call is also equally as fast as subsequent ones.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/simple.jl#L184-L219">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.bisection" href="#Roots.bisection"><code>Roots.bisection</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">bisection(f, a, b; [xatol, xrtol])</code></pre><p>Performs bisection method to find a zero of a continuous function.</p><p>It is assumed that <code>(a,b)</code> is a bracket, that is, the function has different signs at <code>a</code> and <code>b</code>. The interval <code>(a,b)</code> is converted to floating point and shrunk when <code>a</code> or <code>b</code> is infinite. The function <code>f</code> may be infinite for the typical case. If <code>f</code> is not continuous, the algorithm may find jumping points over the x axis, not just zeros.</p><p>If non-trivial tolerances are specified, the process will terminate when the bracket <code>(a,b)</code> satisfies <code>isapprox(a, b, atol=xatol, rtol=xrtol)</code>. For zero tolerances, the default, for <code>Float64</code>, <code>Float32</code>, or <code>Float16</code> values, the process will terminate at a value <code>x</code> with <code>f(x)=0</code> or <code>f(x)*f(prevfloat(x)) &lt; 0</code> or <code>f(x) * f(nextfloat(x)) &lt; 0</code>. For other number types, the <code>Roots.A42</code> method is used.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/simple.jl#L21-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.muller" href="#Roots.muller"><code>Roots.muller</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">muller(f, xᵢ; xatol=nothing, xrtol=nothing, maxevals=100)
muller(f, xᵢ₋₂, xᵢ₋₁, xᵢ; xatol=nothing, xrtol=nothing, maxevals=100)</code></pre><blockquote><p><em>Muller’s method</em> generalizes the secant method, but uses quadratic interpolation among three points instead of linear interpolation between two. Solving for the zeros of the quadratic allows the method to find complex pairs of roots. Given three previous guesses for the root <code>xᵢ₋₂</code>, <code>xᵢ₋₁</code>, <code>xᵢ</code>, and the values of the polynomial <code>f</code> at those points, the next approximation <code>xᵢ₊₁</code> is produced.</p></blockquote><p>Excerpt and the algorithm taken from</p><blockquote><p>W.H. Press, S.A. Teukolsky, W.T. Vetterling and B.P. Flannery <em>Numerical Recipes in C</em>, Cambridge University Press (2002), p. 371</p></blockquote><p>Convergence here is decided by <code>xᵢ₊₁ ≈ xᵢ</code> using the tolerances specified, which both default to <code>eps(one(typeof(abs(xᵢ))))^4/5</code> in the appropriate units. Each iteration performs three evaluations of <code>f</code>. The first method picks two remaining points at random in relative proximity of <code>xᵢ</code>.</p><p>Note that the method may return complex result even for real initial values as this depends on the function.</p><p>Examples:</p><pre><code class="nohighlight hljs">muller(x-&gt;x^3-1, 0.5, 0.5im, -0.5) # → -0.500 + 0.866…im
muller(x-&gt;x^2+2, 0.0, 0.5, 1.0) # → ≈ 0.00 - 1.41…im
muller(x-&gt;(x-5)*x*(x+5), rand(3)...) # → ≈ 0.00
muller(x-&gt;x^3-1, 1.5, 1.0, 2.0) # → 2.0, Not converged</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/simple.jl#L271-L303">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.newton" href="#Roots.newton"><code>Roots.newton</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.newton(f, fp, x0; kwargs...)</code></pre><p>Implementation of Newton&#39;s method: <code>xᵢ₊₁ =  xᵢ - f(xᵢ)/f&#39;(xᵢ)</code>.</p><p>Arguments:</p><ul><li><p><code>f::Function</code> – function to find zero of</p></li><li><p><code>fp::Function</code> – the derivative of <code>f</code>.</p></li><li><p><code>x0::Number</code> – initial guess. For Newton&#39;s method this may be complex.</p></li></ul><p>With the <code>ForwardDiff</code> package derivatives may be computed automatically. For example,  defining <code>D(f) = x -&gt; ForwardDiff.derivative(f, float(x))</code> allows <code>D(f)</code> to be used for the first derivative.</p><p>Keyword arguments are passed to <code>find_zero</code> using the <code>Roots.Newton()</code> method.</p><p>See also <code>Roots.newton((f,fp), x0)</code> and <code>Roots.newton(fΔf, x0)</code> for simpler implementations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/alternative_interfaces.jl#L5-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.dfree" href="#Roots.dfree"><code>Roots.dfree</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">dfree(f, xs)</code></pre><p>A more robust secant method implementation</p><p>Solve for <code>f(x) = 0</code> using an algorithm from <em>Personal Calculator Has Key to Solve Any Equation f(x) = 0</em>, the SOLVE button from the <a href="http://www.hpl.hp.com/hpjournal/pdfs/IssuePDFs/1979-12.pdf">HP-34C</a>.</p><p>This is also implemented as the <code>Order0</code> method for <code>find_zero</code>.</p><p>The initial values can be specified as a pair of two values, as in <code>(a,b)</code> or <code>[a,b]</code>, or as a single value, in which case a value of <code>b</code> is computed, possibly from <code>fb</code>.  The basic idea is to follow the secant method to convergence unless:</p><ul><li><p>a bracket is found, in which case <code>AlefeldPotraShi</code> is used;</p></li><li><p>the secant method is not converging, in which case a few steps of a quadratic method are used to see if that improves matters.</p></li></ul><p>Convergence occurs when <code>f(m) == 0</code>, there is a sign change between <code>m</code> and an adjacent floating point value, or <code>f(m) &lt;= 2^3*eps(m)</code>.</p><p>A value of <code>NaN</code> is returned if the algorithm takes too many steps before identifying a zero.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">Roots.dfree(x -&gt; x^5 - x - 1, 1.0)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/simple.jl#L440-L473">source</a></section></article><h2 id="MATLAB-interface"><a class="docs-heading-anchor" href="#MATLAB-interface">MATLAB interface</a><a id="MATLAB-interface-1"></a><a class="docs-heading-anchor-permalink" href="#MATLAB-interface" title="Permalink"></a></h2><p>The initial naming scheme used <code>fzero</code> instead  of <code>find_zero</code>, following the name of the  MATLAB function <a href="https://www.mathworks.com/help/matlab/ref/fzero.html">fzero</a>. This interface  is not recommended, but, for now, still maintained.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.fzero" href="#Roots.fzero"><code>Roots.fzero</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fzero(f, x0; order=0; kwargs...)
fzero(f, x0, M; kwargs...)
fzero(f, x0, M, N; kwargs...)
fzero(f, x0; kwargs...)
fzero(f, a::Number, b::Number; kwargs...)
fzero(f, a::Number, b::Number; order=?, kwargs...)
fzero(f, fp, a::Number; kwargs...)</code></pre><p>Find zero of a function using one of several iterative algorithms.</p><ul><li><p><code>f</code>: a scalar function or callable object</p></li><li><p><code>x0</code>: an initial guess, a scalar value or tuple of two values</p></li><li><p><code>order</code>: An integer, symbol, or string indicating the algorithm to  use for <code>find_zero</code>. The <code>Order0</code> default may be specified directly  by <code>order=0</code>, <code>order=:0</code>, or <code>order=&quot;0&quot;</code>; <code>Order1()</code> by <code>order=1</code>,  <code>order=:1</code>, <code>order=&quot;1&quot;</code>, or <code>order=:secant</code>; <code>Order1B()</code> by  <code>order=&quot;1B&quot;</code>, etc.</p></li><li><p><code>M</code>: a specific method, as would be passed to <code>find_zero</code>, bypassing the use of the <code>order</code> keyword</p></li><li><p><code>N</code>: a specific bracketing method. When given, if a bracket is identified, method <code>N</code> will be used to finish instead of method <code>M</code>.</p></li><li><p><code>a</code>, <code>b</code>: When two values are passed along, if no <code>order</code> value is specified, <code>Bisection</code> will be used over the bracketing interval <code>(a,b)</code>. If an <code>order</code> value is specified, the value of <code>x0</code> will be set to <code>(a,b)</code> and the specified method will be used.</p></li><li><p><code>fp</code>: when <code>fp</code> is specified (assumed to compute the derivative of <code>f</code>), Newton&#39;s method will be used</p></li><li><p><code>kwargs...</code>: See <code>find_zero</code> for the specification of tolerances and other keyword arguments</p></li></ul><p>Examples:</p><pre><code class="nohighlight hljs">fzero(sin, 3)                  # use Order0() method, the default
fzero(sin, 3, order=:secant)   # use secant method (also just `order=1`)
fzero(sin, 3, Roots.Order1B()) # use secant method variant for multiple roots.
fzero(sin, 3, 4)               # use bisection method over (3,4)
fzero(sin, 3, 4, xatol=1e-6)   # use bisection method until |x_n - x_{n-1}| &lt;= 1e-6
fzero(sin, 3, 3.1, order=1)    # use secant method with x_0=3.0, x_1 = 3.1
fzero(sin, (3, 3.1), order=2)  # use Steffensen&#39;s method with x_0=3.0, x_1 = 3.1
fzero(sin, cos, 3)             # use Newton&#39;s method</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Unlike <code>find_zero</code>, <code>fzero</code> does not specialize on the type of the function argument. This has the advantage of making the first use of the function <code>f</code> faster, but subsequent uses slower.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/alternative_interfaces.jl#L101-L154">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.fzeros" href="#Roots.fzeros"><code>Roots.fzeros</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fzeros(f, a, b; kwargs...)
fzeros(f, ab; kwargs...)</code></pre><p>Searches for all zeros of <code>f</code> within an interval <code>(a,b)</code>. Assumes neither <code>a</code> or <code>b</code> is a zero.</p><p>Compatibility interface for <a href="#Roots.find_zeros"><code>find_zeros</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/alternative_interfaces.jl#L248-L255">source</a></section></article><h2 id="Tracking-iterations"><a class="docs-heading-anchor" href="#Tracking-iterations">Tracking iterations</a><a id="Tracking-iterations-1"></a><a class="docs-heading-anchor-permalink" href="#Tracking-iterations" title="Permalink"></a></h2><p>It is possible to add the keyword argument <code>verbose=true</code>  when calling the <code>find_zero</code> function to get detailed information about the solution and data from each iteration. To save this data a <code>Tracks</code>object may be passed in to <code>tracks</code>.</p><hr/><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Roots.Tracks" href="#Roots.Tracks"><code>Roots.Tracks</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Roots.Tracks{T,S}</code></pre><p>A <code>Tracks</code> instance is used to record the progress of an algorithm. <code>T</code> is the type of function inputs, and <code>S</code> is the type of function outputs. They both default to <code>Float64</code>. Note that because this type is not exported, you have to write <code>Roots.Tracks()</code> to construct a <code>Tracks</code> object.</p><p>By default, no tracking is done while finding a root. To change this, construct a <code>Tracks</code> object, and pass it to the keyword argument <code>tracks</code>. This will modify the <code>Tracks</code> object, storing the input and function values at each iteration, along with additional information about the root-finding process.</p><p><code>Tracks</code> objects are shown in an easy-to-read format. Internally either a tuple of <code>(x,f(x))</code> pairs or <code>(aₙ, bₙ)</code> pairs are stored, the latter for bracketing methods. (These implementation details may change without notice.) The methods <code>empty!</code>, to reset the <code>Tracks</code> object; <code>get</code>, to get the tracks; <code>last</code>, to get the value converted to, may be of interest.</p><p>If you only want to print the information, but you don&#39;t need it later, this can conveniently be done by passing <code>verbose=true</code> to the root-finding function. This will not effect the return value, which will still be the root of the function.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using Roots

julia&gt; f(x) = x^2-2
f (generic function with 1 method)

julia&gt; tracker = Roots.Tracks()
Algorithm has not been run

julia&gt; find_zero(f, (0, 2), Roots.Secant(), tracks=tracker) ≈ √2
true

julia&gt; tracker
Results of univariate zero finding:

* Converged to: 1.4142135623730947
* Algorithm: Secant()
* iterations: 7
* function evaluations ≈ 9
* stopped as |f(x_n)| ≤ max(δ, |x|⋅ϵ) using δ = atol, ϵ = rtol

Trace:
x₁ = 0,	 fx₁ = -2
x₂ = 2,	 fx₂ = 2
x₃ = 1,	 fx₃ = -1
x₄ = 1.3333333333333333,	 fx₄ = -0.22222222222222232
x₅ = 1.4285714285714286,	 fx₅ = 0.04081632653061229
x₆ = 1.4137931034482758,	 fx₆ = -0.0011890606420930094
x₇ = 1.4142114384748701,	 fx₇ = -6.0072868388605372e-06
x₈ = 1.4142135626888697,	 fx₈ = 8.9314555751229818e-10
x₉ = 1.4142135623730947,	 fx₉ = -8.8817841970012523e-16

julia&gt; empty!(tracker)  # resets

julia&gt; find_zero(sin, (3, 4), Roots.A42(), tracks=tracker) ≈ π
true

julia&gt; get(tracker)
4-element Vector{NamedTuple{names, Tuple{Float64, Float64}} where names}:
 (a = 3.0, b = 4.0)
 (a = 3.0, b = 3.157162792479947)
 (a = 3.141592614491745, b = 3.1415926926910007)
 (a = 3.141592653589793, b = 3.141592653589794)

julia&gt; last(tracker)
3.141592653589793</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>As designed, the <code>Tracks</code> object may not record actions taken while the state object is initialized. An example is the default bisection algorithm where an initial midpoint is found to ensure the bracket does not straddle <span>$0$</span>.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaMath/Roots.jl/blob/570940c68fcc0d2baa7cbae154341533b936f96f/src/trace.jl#L27-L108">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../roots/">« Overview</a><a class="docs-footer-nextpage" href="../geometry-zero-finding/">Geometry »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Tuesday 17 September 2024 14:26">Tuesday 17 September 2024</span>. Using Julia version 1.10.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
